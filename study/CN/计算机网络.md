



# WEB页面请求过程

![image-20230201194009289](计算机网络.assets/image-20230201194009289.png)

## 1.HTTP

1. **浏览器做的第一步工作是解析 URL**

![image-20230201194231720](计算机网络.assets/image-20230201194231720.png)

![image-20230201194242046](计算机网络.assets/image-20230201194242046.png)

​	当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是 /index.html 或者 /default.html
​	这些文件，这样就不会发生混乱了

2. 生产HTTP请求报文

![image-20230201194939299](计算机网络.assets/image-20230201194939299.png)

![image-20230201194953305](计算机网络.assets/image-20230201194953305.png)

## 2. DNS

接下来需要委托操作系统把信息发向WEB服务器，这就需要找到WEB服务器域名对应的IP地址

<img src="计算机网络.assets/image-20230201195303296.png" alt="image-20230201195303296" style="zoom:67%;" />

**根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了**

![image-20230201195616612](计算机网络.assets/image-20230201195616612.png)

![image-20230201195632901](计算机网络.assets/image-20230201195632901.png)



## 3. 协议栈

通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈

![image-20230201200113599](计算机网络.assets/image-20230201200113599.png)





## 4. TCP

应用报文从套接字进入协议栈（HTTP基于TCP传输）

**TCP报文段格式**

<img src="计算机网络.assets/image-20230201200545934.png" alt="image-20230201200545934" style="zoom:67%;" />

<img src="计算机网络.assets/image-20230201200859346.png" alt="image-20230201200859346" style="zoom:67%;" />

Linux下的TCP连接

![image-20230201201920701](计算机网络.assets/image-20230201201920701.png)

HTTP请求报文不能超过MSS长度，如果超过，会进行分割

![image-20230201202448591](计算机网络.assets/image-20230201202448591.png)

![image-20230201202536116](计算机网络.assets/image-20230201202536116.png)

在握手成功之后，报文通过WEB服务器默认端口进入

## 5. IP

然后，TCP报文段需要通过协议栈中的IP模块将数据封装成网络包发送给通信对象

IP包头

![image-20230201203600151](计算机网络.assets/image-20230201203600151.png)

当存在多个网卡时，借助路由表来判断**哪个网卡作为源地址IP**，假设 Web 服务器的目标地址是 192.168.10.200

注意：源IP地址就是发送端网卡的IP地址，进行下图操作后，数据包从匹配条目的IFACE项（就是以太网网卡）发送

![image-20230201203934658](计算机网络.assets/image-20230201203934658.png)



## 6. MAC

生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部

MAC头部格式

![image-20230201205057492](计算机网络.assets/image-20230201205057492.png)

MAC 包头的协议类型只使用：0800 ： IP 协议     0806 ： ARP 协议
此时需要知道接收方的MAC地址，需要地址解析协议ARP！

<img src="计算机网络.assets/image-20230201205720728.png" alt="image-20230201205720728" style="zoom:67%;" />

存在ARP缓存

![image-20230201205841841](计算机网络.assets/image-20230201205841841.png)



## 网卡

协议栈的IP模块拿到数据包后，网卡驱动为包加上报头和起始帧定界符，末尾加上FCS（帧校验序列）

![image-20230202195514949](计算机网络.assets/image-20230202195514949.png)



## 交换机

交换机的端口**不核对**接收方MAC地址，而是直接将所有接收到的包放到缓冲区中

交换机根据MAC地址表查找MAC地址，然后将信息发送到对应的端口

如果找不到，则泛洪式广播

如果目的地址是广播地址，则向所有端口广播

MAC地址中的广播地址：FF:FF:FF:FF:FF:FF

<img src="计算机网络.assets/image-20230202200318354.png" alt="image-20230202200318354" style="zoom:67%;" />

## 路由器

交换机的端口不具有MAC地址，但是路由器的每个端口都有IP地址和MAC地址

路由器会对包尾的FCS进行校验

路由器会检查MAC头部，如果和自己端口的MAC地址匹配则接受（交换机不检查，直接接受）

然后查找路由表判断转发目标

将 目的网络号 和路由表中每个条目的子网掩码 相与，匹配，向对应接口转发

![image-20230202201050008](计算机网络.assets/image-20230202201050008.png)



接下来，根据网关列，转发IP数据包，有两种情况：

1. 网关列为空，此时说明IP数据报已经到达了对应网络，则IP数据报头部的IP地址就是目的地址，由ARP获取对应的MAC地址，将查询结果作为接收方的MAC地址
2. 网关列不为空，则数据报继续向该IP地址转发



## 服务器与客户端

层层拆封，提交上层

然后服务器端向客户端发送HTTP响应报文

客户端收到HTTP响应报文后，由浏览器负责渲染

客户端向服务器四挥手



## 从协议角度来看

案例：Bob用笔记本连接学校的以太网交换机，下载WEB页面(www.google.com)

![image-20230202203610788](计算机网络.assets/image-20230202203610788.png)



### 准备：DHCP UDP IP 和 以太网

这里ISP向学校提供DNS服务，所以DNS服务器不再学校里

1. Bob必须要有自己的IP地址，通过DHCP协议，Bob从运行在本地的DHCP服务器上获取配置

   * 在操作系统上生成DHCP请求报文

   * 这个报文被封装在 源端口68 (DHCP客户) 和 目的端口67 (DHCP服务器) 的UDP报文段中

   * UDP报文段被封装在 源IP地址（0.0.0.0）和 广播地址（255.255.255.255）的IP数据报中

2. 该DHCP报文被封装在目的地址FF:FF:FF:FF:FF:FF的帧中，该帧的源MAC地址就是Bob笔记本的MAC地址
3. 该帧会由交换机广播
4. **路由器的接口**（MAC地址为00:22:6B:45:1F) 收到该广播的以太网帧，经过数据的层层解封，提取出DHCP请求报文
5. 假设路由器中的服务器以 CIDR块 68.85.2.0/24 分配IP 地址，假设DHCP 服务器分配地址 68. 85. 2. 101 给Bob 的笔记本
   * DHCP 服务器生成包含这个**IP 地址**以及**DNS 服务器的IP 地址**( 68. 87. 71. 226) 、**默认网关路由器的IP 地址**
     ( 68. 85. 2. l ) 和**子网块**(68. 85. 2. 0/ 24) (等价为“网络掩码) 的一个DHCP ACK 报文
   * 该DHCP ACK报文被封装在源MAC 地址00:22:6B:45:1F:1B) , 目的MAC 地址(00:16:D3:23:68:8A)的以太网帧中

6. 交换机收到路由器发送的数据报，由于之前的**自学习**，交换机向指定端口发送帧
7. 经过层层解封，得到DHCP报文，Bob记录下它的IP 地址和它的DNS 服务器的IP 地址。它还在其IP 转发表中安装默认网关的地址
8. Bob准备处理WEB网页

![image-20230202203610788](计算机网络.assets/image-20230202203610788.png)

### DNS和ARP

Bob在浏览器输入www.google.com

1. 浏览器生成套接字，这个套接字向www.google.com发送HTTP请求，生成这个套接字需要域名www.google.com对应的ip地址，需要DNS
2. 操作系统生成DNS查询报文，www.google.com被放入DNS报文的问题串中，DNS报文被放在目的端口号53的UDP报文段中，该UDP 报文段则被放入具有IP 目的地址68. 87. 71. 226（之前通过DNCP的ACK报文获得），和源IP 地址68.85. 2. 101 的IP 数据报中
3. 此时Bob只知道网关路由器的IP地址（通过DHCP的ACK报文获得），但不知道网关路由器的MAC地址，需要用到ARP协议
4. Bob笔记本生成一个具有目的lP 地址68 . 85. 2. 1(默认网关）的ARP 查询报文将该ARP 报文放置在一个具有广播目的地址(FF: FF: FF:FF: FF:FF ) 的以太网帧中，向交换机发送这个帧，这个帧最终会被交付到网关路由器
5. 网关路由器连接学校的接口收到该帧，发现ARP报文中的目标IP地址68 . 85.2. 1 匹配其接口的IP 地址。网关路由器准备一个**ARP回答**，指示它的MAC 地址00: 22: 6B: 45 : 1F: 1B 对应IP 地址68. 85. 2. 1，这个ARP回答报文放在目的地址为00: 16: D3: 23: 68: 8A（Bob的笔记本）的帧中
6. Bob接收ARP回答，从中抽取出网关路由器的MAC地址( 00 : 22: 6B: 45: 1F: 1B)
7. 至此Bob获取了网关路由器的MAC地址
8. Bob向交换机发送目的IP地址68. 87. 71. 226 (DNS 服务器），目的MAC地址00:22 : 6B:45: 1F: 1B (网关路由器）的帧

![image-20230202203610788](计算机网络.assets/image-20230202203610788.png)

### 域内路由选择

1. 网关路由器收到该帧，抽取出目的IP地址（DNS服务器的IP地址），根据其路由表，转发到Comcast网络左边的路由器
2. Comcast网络中左边的路由器收到帧，拆出IP地址，根据转发表，选择出接口，转发表己根据Comcast 的域内协议（如RIP 、OSPF 或IS-IS）以及因特网的域间协议BGP所填写
3. 然后DNS报文到达DNS服务器，DNS抽取出DNS报文，在数据库中查找谷歌对应的IP地址的**源记录**，假设缓存命中，DNS服务器发送DNS回答报文
4. 该报文到达Bob笔记本，抽取出DNS服务器的IP地址

### TCP和HTTP

1. 因为Bob已经有了www.google.com（WEB服务器）的IP地址，所以可以生成TCP套接字（这个套接字为了向服务器发送HTTP GET报文），与此同时，Bob笔记本的套接字向WEB服务器的套接字**TCP三握手**，Bob首先生成目的端口号80（HTTP）的TCP SYN 报文段， 报文段放在目的地址64. 233. 169. 105的IP数据报中，该数据报放置在MAC 地址为00:22:68:45: IF: 1B ( 网关路由器）的帧中，并向交换机发送该帧
2. 包含TCP SYN的数据报被路由器转发，转发规则由域内路由协议，域间路由协议共同完成
3. 最终，包含TCP SYN 的数据报到达www. google. com，拆解出TCP SYN报文，该报文被送到端口号80的**欢迎套接字**，之后**生成连接套接字**，产生一个TCP SYNACK 报文段
4. 包含TCP SYNACK报文段的数据报到达Bob，进入Bob对应端口的套接字，进入连接状态
5. Bob 的浏览器生成包含要获取的URL 的HTTP GET 报文，发往WEB服务器
6. 在www. google. com 的HTTP 服务器从TCP 套接字读取HTTP GET 报文，生成一个HTTP 响应报文，将请求的Web 页内容放入HTTP 响应体中，并将报文发送进TCP 套接字中
7. 包含HTTP 回答报文的数据报到达Bob，Bob 的Web 浏览器程序从套接字读取HTTP 响应，从HTTP 响应体中抽取Web 网页的html, 并最终显示了Web 网页

​     











# 网络安全

## 基本概念

密钥（KA）：数字或者字符，作为加密算法的输入

加密算法：用加密一方的密钥和明文报文（m)  作为输入

解密算法：用解密一方的密钥和密文报文（KA（m)  ）作为输入

报文摘要:（Message Digest）

散列报文鉴别码（Hashed MAC，HMAC) : 直接使用密码散列函数实现报文鉴别的技术, 不需要进行加密

数字签名（Digital Signature）：在计算机网络中传送的报文可以使用数字签名来证明其真实来源

实体鉴别：通信双方的一方验证另一方身份的技术，常简称为鉴别，实体可以是人、客户进程或服务器进程

不重数（nonce）：用来应对重放攻击，不重数可以使用户把重复的实体鉴别请求和新的实体鉴别请求区分开

密钥分配中心（Key Distribution Center，KDC）：其任务就是给需要进行秘密通信的用户临时分配一个会话密钥

![image-20230128201113780](计算机网络.assets/image-20230128201113780.png)

![image-20230128200743914](计算机网络.assets/image-20230128200743914.png)

## 对称密钥密码体制和公钥密码体制

### 公钥密码体制产生原因

![image-20230128201511165](计算机网络.assets/image-20230128201511165.png)

![image-20230128202513612](计算机网络.assets/image-20230128202513612.png)

注意：

PK只能用来加密，不能用来解密

公钥密码体制通常用于会话密钥的建立

## 报文摘要和报文鉴别码

为什么有报文摘要？因为总比加密这么长的报文效果要好

下图间的密钥只在双方间共享

加密后的报文摘要附在报文后面，称为报文鉴别码（MAC）

对于发送方产生的报文x和其相应的报文摘要H(x)，攻击者不可能伪造出另一个报文y，使得y与x具有同样的报文摘要

报文摘要算法：MD-5 ， SHA-1

![image-20230128202725979](计算机网络.assets/image-20230128202725979.png)

![image-20230128204407122](计算机网络.assets/image-20230128204407122.png)

<img src="计算机网络.assets/image-20230128204623824.png" alt="image-20230128204623824" style="zoom:67%;" />



## 数字签名

![image-20230131194441930](计算机网络.assets/image-20230131194441930.png)

![image-20230131195029731](计算机网络.assets/image-20230131195029731.png)

![image-20230131195252867](计算机网络.assets/image-20230131195252867.png)

**上面这种数字签名存在问题**

![image-20230131195346948](计算机网络.assets/image-20230131195346948.png)

**所以用下面这种保密性数字签名**

![image-20230131195403818](计算机网络.assets/image-20230131195403818.png)



## 实体鉴别

不重数可以使用户把重复的实体鉴别请求和新的实体鉴别请求区分开

![image-20230131200353103](计算机网络.assets/image-20230131200353103.png)

![image-20230131200751397](计算机网络.assets/image-20230131200751397.png)

![image-20230131201502729](计算机网络.assets/image-20230131201502729.png)

![image-20230131201846925](计算机网络.assets/image-20230131201846925.png)

所以需要CA



## 密钥分发

### 对称密钥的分发

![image-20230131202540009](计算机网络.assets/image-20230131202540009.png)

![image-20230131202719167](计算机网络.assets/image-20230131202719167.png)

### 公钥的分发

随意分发公钥的安全隐患

![image-20230131202941949](计算机网络.assets/image-20230131202941949.png)

因此，需要有一个值得信赖的机构将公钥与其对应的实体（人或机器）进行绑定（binding）。这种机构被称为认证中心（Certification Authority，CA），一般由政府出资建立

需要发布公钥的用户可以让CA**为其公钥**签发一个证书（Certification），**证书中包含有公钥及其拥有者的身份标识信息**（人名、公司名或IP地址等）

![image-20230131204212390](计算机网络.assets/image-20230131204212390.png)

![image-20230124211637780](计算机网络.assets/image-20230124211637780.png)

公钥基础结构（Public Key Infrastructure，PKI）

![image-20230131204614680](计算机网络.assets/image-20230131204614680.png)







## 攻击手段

![image-20230128200627819](计算机网络.assets/image-20230128200627819.png)

<img src="计算机网络.assets/image-20230128200648802.png" alt="image-20230128200648802" style="zoom: 67%;" />

![image-20230131195950301](计算机网络.assets/image-20230131195950301.png)





# 应用层

## HTTP(Hyper Text Transfer Protocol)

### 一些术语

**Web页面(文档）**

是由**对象**组成的。一个对象只是一个文件，诸如一个HTML 文件、一个JPEG 图形、一个Java 小程序或一个视频片段这样的文件，且它们可通过一个URL 地址寻址。

多数Web 页面含有一个HTML基本文件(base HTML file) 以及几个引用对象

HTML 基本文件通过对象的URL 地址引用页面中的其他对象

**URL的组成：**

* 存放对象的服务器主机名

* 对象的路径名

  比如 http: //www. someSchoo1. edu/ someDepartment/ picture.gif

  www. someSchoo1. edu是主机名，/someDepartment/ picture. gif 就是路径名



### HTTP的基本思想

当用户请求一个**Web 页面**（如点击一个超链接）时，浏览器向服务器发出对该页面中所包含对象的HTTP请求报文， 服务器接收到请求并用服务器的服务器包含这些对象的HTTP 响应报文进行响应

使用TCP为支撑协议，客户和服务器分别向其套接字接口发送和接受报文，一旦客户端向套接字发送了报文，报文就脱离了客户端的控制，转而由TCP控制

![image-20230127205259259](计算机网络.assets/image-20230127205259259.png)



HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据
的「约定和规范」。

基于TCP/IP，采用请求-应答的通信模式

文本：字符、图片、视频、压缩包等

超文本：文字、图片、视频等的混合体，超链接可以从一个超文本跳转到另一个超文本，HTML是最常见的超文本

* 进程与进程之间通信，具体来说，是客户的浏览器进程和WEB服务器进程间的通信，通过TCP连接，互相发送HTTP请求报文和HTTP响应报文

![image-20230123193408210](计算机网络.assets/image-20230123193408210.png)

* 建立在TCP连接（熟知端口号80）之上
* 两点之间传输的双向协议

### 不同版本的HTTP

* HTTP1.0

采用非持续连接方式，即浏览器每次请求一个文件，都要与服务器建立TCP连接，收到响应后立即关闭TCP连接

每请求一个文档就要有两倍的RTT的开销。若一个网页上有很多引用对象（例如图片等），那么请求每一个对象都需要花费2RTT的时间

![image-20230123195231627](计算机网络.assets/image-20230123195231627.png)

为了减小时延，浏览器通常会建立多个并行的TCP连接同时请求多个对象。但是，这会大量占用万维网服务器的资源，特别是万维网服务器往往要同时服务于大量客户的请求，这会使其负担很重。

​	HTTP1.0 的连接方式

![image-20230128191332375](计算机网络.assets/image-20230128191332375.png)

* HTTP1.1

采用持续连接方式

报文的格式是**纯文本**形式的

万维网服务器在发送响应后仍然保持这条连接

HTTP/1.1的持续连接还可以使用流水线方式工作(浏览器在收到HTTP的响应报文之前就能够连续发送多个请求报文)

​	HTTP1.1的性能瓶颈

1. 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分；
   发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
2. 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队
   头阻塞；
3. 没有请求优先级控制；
4. 请求只能从客户端开始，服务器只能被动响应。

* HTTP报文格式

HTTP是面向文本的，其报文中的每一个字段都是一些ASCII码串，并且每个字段的长度都是不确定的。

方法和字段：

Host字段（首部字段）：用来指定服务器的域名

Content-Length 字段：表明本次回应的数据长度

Connection 字段：要求服务器使用 TCP 持久连接，以便其他请求复用

User_agent字段：指明用户代理（浏览器）这样服务器就可以为不同的用户代理发送相同对象的不同版本

<img src="计算机网络.assets/image-20230124202849053.png" alt="image-20230124202849053" style="zoom:67%;" />

正因为HTTP1.1以长连接为基础，所以在一个TCP连接中，客户端可以同时发出多个请求，可以采用管道传输

<img src="计算机网络.assets/image-20230124203538980.png" alt="image-20230124203538980" style="zoom:67%;" />	`

![image-20230123205434968](计算机网络.assets/image-20230123205434968.png)

Content-Type 字段：用于服务器回应时，告诉客户端，本次数据是什么格式

![image-20230123205602605](计算机网络.assets/image-20230123205602605.png)

![image-20230123200801071](计算机网络.assets/image-20230123200801071.png)



![image-20230123201001683](计算机网络.assets/image-20230123201001683.png)

![image-20230123204626034](计算机网络.assets/image-20230123204626034.png)

![image-20230123200511032](计算机网络.assets/image-20230123200511032.png)

### Get和Post有什么区别？

Get：请求从服务器**获取**资源

<img src="计算机网络.assets/image-20230123210047186.png" alt="image-20230123210047186" style="zoom: 67%;" />

Post：向 URI 指定的资源**提交**数据，数据就放在报文的 body 里。

<img src="计算机网络.assets/image-20230124201741388.png" alt="image-20230124201741388" style="zoom:67%;" />

* Get方法实体体为空，而Post方法实体体不为空
* HTTP响应报文的实体体中存放着请求的文档数据
* HTTP响应报文的Last_Modified首部行对既可能在本地客户也可能在网络缓存服务器上的对象缓存来说非常重要

### GET 和 POST 方法都是安全和幂等的吗？

安全: 请求方法不会「破坏」服务器上的资源

幂等: 多次执行相同的操作，结果都是「相同」的

GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。
POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。

### HTTP的缺点

1. 无状态。解决方法：cookie
2. 明文传输，容易被窃取
3. 不安全 解决方法：TLS/SSL

### HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

1. 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
2. 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求
   出去，可以减少整体的响应时间

### HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

HTTP/2 相比 HTTP/1.1 性能上的改进：

1. 头部压缩

   如果多个请求头部一样或相似，就回消除重复部分——HPACK算法，：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

2. 二进制

   格式头信息和数据体都是二进制（而不是HTTP1.1的文本），并且统称为帧（frame）：头信息帧和数据帧。增加传输效率

<img src="计算机网络.assets/image-20230125214027372.png" alt="image-20230125214027372" style="zoom: 50%;" />

3. 数据流

   数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必
   须要对数据包做标记，指出它属于哪个回应。**每个请求或回应的所有数据包**，称为一个数据流（ Stream ）, 客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

4. 优先级

   客户端还可以指定**数据流的**优先级。优先级高的请求，服务器就先响应该请求。

<img src="计算机网络.assets/image-20230125215103568.png" alt="image-20230125215103568" style="zoom:50%;" />

5. 多路复用

   HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。
   移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。

   <img src="计算机网络.assets/image-20230125215411710.png" alt="image-20230125215411710" style="zoom:50%;" />

6. 服务器推送

   HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以主动
   向客户端发送消息。
   举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给
   客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。

### HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？

HTTP/2 主要的问题在于，**多个 HTTP 请求在复用一个 TCP 连接**，下层的 TCP 协议是不知道有多少个
HTTP 请求的。所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有
的 HTTP 请求都必须等待这个丢了的包被重传回来。

* HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞，那么队列后请求也统统被阻塞住了
* HTTP/2 多个请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。

所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！

基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。

头部压缩算法升级成了QPack

HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。

<img src="计算机网络.assets/image-20230125220111796.png" alt="image-20230125220111796" style="zoom:67%;" />

<img src="计算机网络.assets/image-20230125220348330.png" alt="image-20230125220348330" style="zoom:80%;" />

## HTTPS

HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式

### HTTP与HTTPS有什么区别

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全
的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP
三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

<img src="计算机网络.assets/image-20230124204144362.png" alt="image-20230124204144362" style="zoom:50%;" />

### HTTPS的解决方案

* HTTP的**窃听**危机——**机密性**——HTTPS解决：采用**混合加密**

**混合加密**：保证信息的机密性，解决了窃听的风险

在通信建立**前**采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
在通信过程**中**全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

**为什么采用混合加密？**

对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但
速度慢。

<img src="计算机网络.assets/image-20230124205448727.png" alt="image-20230124205448727" style="zoom:67%;" />

* HTTP的**篡改**风险——**完整性**——HTTPS解决：采用**摘要算法**

**摘要算法**：用来实现完整性，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。

![image-20230124210706971](计算机网络.assets/image-20230124210706971.png)

* HTTP**的冒充风险**——**实体鉴别**——HTTPS解决：将服务器**公钥放入数字证书**中

客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密

有一个问题：如何保证公钥不被篡改和信任度？——解决方法：CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

![image-20230124211637780](计算机网络.assets/image-20230124211637780.png)

### HTTPS的连接过程

1. 客户端向服务器索要并验证服务器的公钥。
2. 双方协商生产「会话秘钥」。
3. 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是握手阶段。

**SSL/TLS四握手**

见小林图解网络P19

[点击这里](F:\Caoyan\program\cpp\计算机网络\亮白风格-图解网络-小林coding-v2.0.pdf)

## Cookie

背景：HTTP是无状态协议，需要Cookie来保留状态，需要万维网服务器能够识别用户，对无状态的HTTP进行状态化的技术

**Cookie的组件**

1. 在HTTP 响应报文中的一个cookie **首部行**； 
2. 在HTTP 请求报文中的一个cookie **首部行**； 

3. 在用户端系统中保留有一个cookie 文件，并由用户的浏览器进行管理； 

4. 位于Web 站点的一个后端数据库

工作流程

3. 这个HTTP响应报文包含有一个首部字段“Set-Cookie"的首部行

![image-20230123202036179](计算机网络.assets/image-20230123202036179.png)

![image-20230128195215429](计算机网络.assets/image-20230128195215429.png)



# 运输层

## 基本知识

### 端口号

端口号只具有本地意义

<img src="计算机网络.assets/image-20230217131344629.png" alt="image-20230217131344629" style="zoom:67%;" />

<img src="计算机网络.assets/image-20230217131740020.png" alt="image-20230217131740020" style="zoom:67%;" />















## TCP三握手四挥手

### 什么是TCP

面向连接的，可靠的，基于字节流的运输层协议

面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的

可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

字节流：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃

**为什么需要TCP？**网络层的IP协议是不可靠的

### TCP头部格式

![image-20230217134348316](计算机网络.assets/image-20230217134348316.png)



* **序列号：**

  在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来**解决网络包乱序**问题。

  占32比特，取值范围0~232-1。当序号增加到最后一个时，下一个序号又回到0。用来指出`本TCP报文段数据载荷的第一个字节的序号`

* **确认应答号：**

  指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决不丢包的问题。

  占32比特，取值范围0~232-1。当确认号增加到最后一个时，下一个确认号又回到0。用来指出`期望收到对方下一个TCP报文段的数据载荷的第一个字节的序号`，同时也是对之前收到的所有数据的确认

* **控制位：**

  `ACK`：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN包之外该位必须设置为 1 
  `RST`：复位TCP连接。当RST=1时，表明TCP连接中出现严重差错，必须释放连接，然后再重新建立连接。RST置1还用来拒绝一个非法的TCP报文段或拒绝打开一个TCP连接

  `SYN`：该位为 1 时，表示**希望建立连接**，并在其「序列号」的字段进行**序列号初始值的设定**, SYN为1的TCP报文段要么是一个`连接请求报文段`，要么是一个`连接响应报文段`
  `FIN`：该位为 1 时，表示今后**不会再有数据发送**，**希望断开连接**。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段

  `PSH`：推送标志位，**发送方**TCP把PSH置1，并立即创建一个TCP报文段发送出去，而不需要积累到足够多的数据再发送。**接收方**TCP收到PSH为1的TCP报文段，就尽快地交付给应用进程，而不再等到接收到足够多的数据才向上交付。

* **首部长度（数据偏移）：**以4字节为单位

* **窗口**：

  占16比特，该字段的取值以`字节`为单位。
  指出发送本报文段的一方的`rwnd`的大小，即接收缓存的可用空间大小，这用来表征接收方的接收能力
  实现流量控制

* **紧急指针：**

  当发送方有紧急数据时，可将紧急数据“插队”到发送缓存的最前面，并立刻封装到一个TCP报文段中进行发送。紧急指针会指出本报文段数据载荷部分包含了多长的紧急数据，紧急数据之后是普通数据。
  接收方收到紧急标志位为1的TCP报文段，会按照紧急指针字段的值从报文段数据载荷中取出紧急数据并直接上交应用进程，而不必在接收缓存中排队。

* **选项：**

  <img src="计算机网络.assets/image-20230217140114708.png" alt="image-20230217140114708" style="zoom: 80%;" />

* **填充：**确保TCP首部长度能被4字节整除

  



### TCP连接建立的准备

建立一个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识

1. Socket：由 IP 地址和端口号组成

2. 序列号：用来解决乱序问题等

3. 窗口大小：用来做流量控制



**源IP地址，目的IP地址，源端口号，目的端口号可以唯一确定一个TCP连接**



理论上：

![image-20230208165115768](计算机网络.assets/image-20230208165115768.png)

但是服务端最大连接数达不到这个数量，因为：

1. 文件描述符限制：Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目
2. 内存限制：每个 TCP 连接都要占用一定内存，操作系统的内存是有限的



### TCP数据载荷长度计算方法

![image-20230208171730465](计算机网络.assets/image-20230208171730465.png)

其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度



### TCP与UDP的区别

![image-20230208163347939](计算机网络.assets/image-20230208163347939.png)

<img src="计算机网络.assets/image-20230208165834993.png" alt="image-20230208165834993"  />

1. 连接

   TCP是面向连接的传输层协议，传输数据前先要建立连接。 UDP是不需要连接，即刻传输数据。

2. 服务对象

   TCP是一对一的两点服务，仅支持单播。 UDP 支持单播、多播、广播

3. 可靠性

   TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努力交付，不保证可靠交付数据。

4. 拥塞控制、流量控制

   TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率

5. 首部开销

   TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长，首部最大60字节。UDP 首部只有 8 个字节，并且是固定不变的，开销较小

6. 传输方式

   TCP 是流式传输，没有边界，但保证顺序和可靠。UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序

7. 分片不同

   TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要**传输丢失的这个分片**。
   UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了一个分片，则就需要**重传所有的数据包**，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU

8. UDP是面向应用报文的，TCP是面向字节流的

**应用场景**

TCP: FTP HTTP HTTPS

UDP: DNS SNMP 广播 音视频

TCP 有**可变长**的「选项」字段，而 UDP 头部长度则是**不会变化**的，无需多一个字段去记录UDP 的首部长度

UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段，因为首部长度需要是 4 字节的整数倍



### TCP三握手

![image-20230208171900633](计算机网络.assets/image-20230208171900633.png)

![image-20230208172143004](计算机网络.assets/image-20230208172143004.png)![image-20230208172220914](计算机网络.assets/image-20230208172220914.png)

![image-20230208172253781](计算机网络.assets/image-20230208172253781.png)

### 为什么是“三”握手？

关键：为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接（实际上就是交换连接需要的状态信息）

**首要原因：了防止旧的重复连接初始化造成混乱**

![image-20230208173222740](计算机网络.assets/image-20230208173222740.png)

<img src="计算机网络.assets/image-20230217141009676.png" alt="image-20230217141009676" style="zoom:67%;" />

如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接



**原因二：同步双方初始序列号**

![image-20230208174021541](计算机网络.assets/image-20230208174021541.png)



**原因三：避免资源浪费**

![image-20230208174322956](计算机网络.assets/image-20230208174322956.png)

两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 SYN 报文，而造成重复分配资源

而三握手只会在最后一次握手成功后分配资源

**总结**

三握手：能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号

二握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号

四握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数



### **为什么客户端和服务端的初始序列号 ISN 是不相同的？**

如果一个已经失效的连接被重用了，但是该旧连接的历史报文还残留在网络中，如果序列号相同，那么就无法分辨出该报文是不是**历史报文**，如果历史报文被新的连接接收了，则会产生数据错乱。
所以，每次建立连接前重新初始化一个序列号主要是为了通信双方能够根据序号将不属于本连接的报文段丢弃。
另一方面是为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收



### 随机ISN的产生

RFC1948 中提出了一个较好的初始化序列号 ISN 随机生成算法。
ISN = M + F (localhost, localport, remotehost, remoteport)
M 是一个计时器，这个计时器每隔 4 毫秒加 1。
F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择



### 为什么 TCP 层还需要 MSS 呢？

**关键：在运输层分片而不是在网络层分片，运输层分片重传时只要重传丢失的分组，但是网络层分片重传时需要重传所有分组**

![image-20230210132811006](计算机网络.assets/image-20230210132811006.png)

IP层有一个大于MTU的数据要发送，需要分片，目的主机组装这些分片，再上交给TCP

IP层没有超时重传机制，需要TCP控制超时和重传

接收方发现一个IP分片丢失，所有分片都要重传

当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后（IP分片丢失），则不会响应 ACK 给对方，那么发送方的TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」

所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，**当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了**

这样，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传效率

### 关于SYN攻击

假设攻击者短时间**伪造不同 IP 地址**的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，**无法得到未知 IP 主机的 ACK 应答**，久而久之就会占满服务端的 **SYN 接收队列**，使得服务器不能为正常用户服务

<img src="计算机网络.assets/image-20230210135208989.png" alt="image-20230210135208989" style="zoom:67%;" />



**避免方法一**

队列快满时，丢弃SYN报文（对新的SYN返回RST），设置SYN_RCVD状态的最大连接数

此时网卡接收数据包的速度会大于内核处理速度，数据报会进入缓冲队列，可以调整这个缓冲队列的大小

**避免方法二**

Linux 内核的 SYN （未完成连接建立）队列与 Accpet （已完成连接建立）队列的工作：

<img src="计算机网络.assets/image-20230210140152408.png" alt="image-20230210140152408" style="zoom: 80%;" />

1. 当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 SYN 队列」

2. 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文

3. 服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 Accept 队列」

4. 应用通过调用 accpet() socket 接口，从「 Accept 队列」取出连接

   **tcp_syncookies 的方式可以应对 SYN 攻击的方法：**

<img src="计算机网络.assets/image-20230210140315907.png" alt="image-20230210140315907" style="zoom:80%;" />

<img src="计算机网络.assets/image-20230210140332655.png" alt="image-20230210140332655" style="zoom: 80%;" />

1. 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」
2. 计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回**客户端**，服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，**直接放入到「 Accept 队列」**
3. 最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接



### TCP四挥手

客户端和服务端都可以主动断开连接

TCP规定终止标志位FIN等于1的TCP报文段即使不携带数据，也要消耗掉一个序号

![image-20230217142634962](计算机网络.assets/image-20230217142634962.png)



#### 为什么需要四挥手？

比如客户端向服务器发送FIN，代表客户端向服务器这个方向的连接断开，但是服务器还是可以向客户端发送数据



#### **为什么TIME_WAIT等于2MSL？**

首先要区分TTL和MSL：

MSL： Maximum Segment Lifetime，报文最大生存时间，超过这个时间报文会被丢弃

TTL：IP数据报可经过的最大路由数（最大跳数），在IP头部中

2MSL：客户端收到服务端的FIN，进入TIME_WAIT，但客户端随后发送的ACK报文丢失，从而导致服务端重发FIN，这样正好两个MSL

Linux中，内核代码中包含了TCP的TIME_WAIT时间（60s）。 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒

```c
#define TCP_TIMEWAIT_LEN (60*HZ) /* how long to wait to destroy TIME-WAIT
```



#### 为什么需要TIME_WAIT状态？

##### TIME_WAIT过短

**原因一：防止旧连接数据包造成数据扰乱**

![image-20230211145808063](计算机网络.assets/image-20230211145808063.png)

如上图黄色框框服务端在关闭连接之前发送的 SEQ = 301 报文，被网络延迟了。
这时有相同端口的 TCP 连接被复用后，被延迟的 SEQ = 301 抵达了客户端，那么客户端是有可能正常接收这个过期的报文，这就会产生数据错乱等严重的问题。

所以，TCP 就设计出了这么一个机制，经过 2MSL 这个时间，**足以让两个方向上的数据包都被丢弃**，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。



**原因二：保证连接的正常关闭**

![image-20230211150936944](计算机网络.assets/image-20230211150936944.png)

![image-20230217143021877](计算机网络.assets/image-20230217143021877.png)

注意，正常情况下TIME_WAIT比较长，如果最后一个ACK丢失，服务端会重传FIN报文



##### TIME_WAIT过长

* 占用内存资源
* 占用端口资源，一个 TCP 连接至少消耗一个本地端口

具体来说

客户端一共只有65536个端口，端口满了，新的连接没发建立

因为TCP连接四元组，服务端理论上可以建立比较多的TCP连接，但是由于服务器的线程池只有固定数量的线程被拿来用于建立TCP连接，所以新连接可能无法建立



#### 如何优化TIME_WAIT?

**方法一：net.ipv4.tcp_tw_reuse 和 tcp_timestamps**

如下的 Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用

```c
net.ipv4.tcp_tw_reuse = 1
```

在这之前需要打开TCP时间戳的支持

```c
net.ipv4.tcp_timestamps=1（默认即为 1）
```

tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用connect() 函数时，**内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用**

这个时间戳的字段在 TCP 头部的「选项」里，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间戳
由于引入了时间戳，**在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃**



**方式二：程序中使用 SO_LINGER**

以通过设置 socket 选项，来设置调用 close 关闭连接行为

```c
struct linger so_linger;
so_linger.l_onoff = 1;
so_linger.l_linger = 0;
setsockopt(s, SOL_SOCKET, SO_LINGER, &so_linger,sizeof(so_linger));
```

如果l_onoff 为非 0， 且l_linger 值为 0，那么调用close 后，会立该发送一个RST 标志给对端，该TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT 状态，直接关闭
但这为跨越TIME_WAIT 状态提供了一个可能，不过是一个非常危险的行为，不值得提倡



#### 已经建立了连接，但客户端突然出现故障了怎么办？

TCP存在**保活机制**，该机制通过每隔一段时间，发送包含少量数据的**探测报文**监视TCP连接相关的活动，如果一段时间内没有检测到活动，判断该TCP死亡，通知上层

**有下面三种情况：**

1. 探测报文被正常接收，那保活时间重置
2. 对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端可以响应，但由于没有该连接的有效信息，会产生一个 **RST 报文**，这样很快就会发现 TCP 连接已经被重置
3. 是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端
   后，连续几次无响应，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡





Linux内核中的参数：

tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接
相关的活动，则会启动保活机制
tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；
tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。

**total time = tcp_keepalive_time + tcp_keepalive_intvl * tcp_keepalive_probes**



#### Socket编程

![image-20230212103831316](计算机网络.assets/image-20230212103831316.png)

* 服务端和客户端初始化 socket ，得到文件描述符；
* 服务端调用 bind ，将绑定在 IP 地址和端口;
* 服务端调用 listen ，进行监听；
* 服务端调用 accept ，等待客户端连接；
* 客户端调用 connect ，向服务器端的地址和端口发起连接请求；
* 服务端 accept 返回用于传输的 socket 的文件描述符；
* 客户端调用 write 写入数据；服务端调用 read 读取数据；
* 客户端断开连接时，会调用 close ，那么服务端 read 读取数据的时候，就会读取到了EOF ，待处理完数据后，服务端调用 close ，表示连接关闭

这里需要注意的是，**服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket**，后续用来传输数据

也就是说监听socket和传输数据的socket不一样，一个是欢迎套接字，一个是传输套接字

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，**就像往一个文件流里面写东西一样**。

<img src="计算机网络.assets/image-20230212105524171.png" alt="image-20230212105524171" style="zoom:80%;" />



Linux内核中会维护两个队列：

未完成连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；

已完成连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；



现在通常认为 backlog 是 accept 队列。

但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog,somaxconn)



<img src="计算机网络.assets/image-20230212110928938.png" alt="image-20230212110928938" style="zoom:80%;" />

应用程序从connect 调用返回，表示客户端到服务器端的单向连接建立成功，客户端进入ESTABLISHED状态。

服务器端协议栈使得 accept 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务端进入ESTABLISHED状态。

**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**



<img src="计算机网络.assets/image-20230212111442491.png" alt="image-20230212111442491" style="zoom: 80%;" />

* 客户端调用 close ，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入FIN_WAIT_1 ；
* 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，**应用程序可以通过 read 调用来感知这个 FIN 包**。**这个 EOF 会被放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；
* 接着，**当处理完数据后，自然就会读到 EOF** ，于是也调用 close 关闭它的套接字，这会使得客户端会发出一个 FIN 包，之后处于 LAST_ACK 状态；
* 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT ；
* 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
* 客户端经过 2MSL 时间之后，也进入 CLOSE 状态；



#### 几个问题

1. 为了方便调试服务器程序，一般会在服务端设置 SO_REUSEADDR 选项，这样服务器程序在重启后，可以立刻使用。这里设置SO_REUSEADDR 是不是就等价于对这个 socket 设置了内核中的 net.ipv4.tcp_tw_reuse=1 这个选项？

   tcp_tw_reuse 是内核选项，主要用在连接的发起方（客户端）。TIME_WAIT 状态的连接创建时间超过 1 秒后，新的连接才可以被复用，注意，这里是「连接的发起方」；

   SO_REUSEADDR 是用户态的选项，用于「连接的服务方」，用来告诉操作系统内核，如果端口已被占用，但是 TCP 连接状态位于 TIME_WAIT ，可以重用端口。如果端口忙，而 TCP 处于其他状态，重用会有 “Address already in use” 的错误信息。tcp_tw_reuse 是为了缩短 time_wait 的时间，避免出现大量的 time_wait 连接而占用系统资源，解决的是 accept 后的问题。
   SO_REUSEADDR 是为了解决 time_wait 状态带来的端口占用问题，以及支持同一个 port 对应多个
   ip，解决的是 bind 时的问题。

2. 如果客户端第四次挥手ack丢失，服务端超时重发的fin报文也丢失，客户端timewait时
   间超过了2msl，这个时候会发生什么？认为连接已经关闭吗？

   当客户端 timewait 时间超过了 2MSL，则客户端就直接进入关闭状态。
   服务端超时重发 fin 报文的次数如果超过 tcp_orphan_retries 大小后，服务端也会关闭 TCP 连接

3. （1）IP按MTU分片，如果某一片丢失则需要所有分片都重传；（2）IP没有重传机制，所以需要等TCP发送方超时才能重传；问题一：MSS跟IP的MTU分片相比，只是多了一步协商MSS值的过程，而IP的MTU可以看作是默认协商好就是1500字节，所以为什么协商后的MSS可以做到丢失后只发丢失的这一片来提高效率，而默认协商好1500字节的IP分片就需要所有片都重传呢？问题二：TCP MSS分片如果丢失了一片，是不是也需要
   发送方等待超时再重传？如果不是，MSS的协商如何能在超时前就直到丢了分片从而提高效率的呢？

   **问题一：**
   如果一个大的 TCP 报文是被 MTU 分片，那么只有「第一个分片」才具有 TCP 头部，后面的分片则没有 TCP 头部，接收方 IP 层只有重组了这些分片，才会认为是一个 TCP 报文，那么丢失了其中一个分片，接收方 IP 层就不会把 TCP 报文丢给 TCP 层，那么就会等待对方超时重传这一整个TCP 报文。
   如果一个大的 TCP 报文被 MSS 分片，那么所有「分片都具有 TCP 头部」，因为每个 MSS 分片的是具有 TCP 头部的TCP报文，那么其中一个 MSS 分片丢失，就只需要重传这一个分片就可以。
   **问题二：**
   TCP MSS分片如果丢失了一片，发送方没收到对方ACK应答，也是会触发超时重传的，因为TCP层是会保证数据的可靠交付。

4. 如果是服务提供方发起的 close ，然后引起过多的 time_wait 状态的 tcp 链接，time_wait 会影响服务端的端口吗？

   不会。
   如果客户端的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。
   **客户端受端口资源限制：**
   客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新连接。
   **服务端受系统资源限制：**
   由于一个 TCP 四元组表示 TCP 连接，理论上服务端可以建立很多连接，服务端只监听一个端口，但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。所以当服务端出现大量 TIMEWAIT 时，系统资源容易被耗尽。





## TCP中的各种机制

### 重传机制

#### 超时重传

**产生条件**

数据包丢失或者确认应答丢失

![image-20230214145804749](计算机网络.assets/image-20230214145804749.png)

**超时重传时间太大或太小？**

![image-20230214150057742](计算机网络.assets/image-20230214150057742.png)

所以超时重传时间（RTO） 的值应该略大于报文往返 RTT 的值



**超时重传时间（RTO）的计算**

由于RTT会变化，所以RTO也会变化

![image-20230214150638499](计算机网络.assets/image-20230214150638499.png)

在 Linux 下，α = 0.125，β = 0.25， μ = 1，∂ = 4。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍**。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送



#### 快重传

**产生条件**

收到三个**相同**的ACK

<img src="计算机网络.assets/image-20230214151022045.png" alt="image-20230214151022045" style="zoom:80%;" />



#### SACK（Selective Acknowledgement ）选择性确认

这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。

**SACK产生于接收方收到异常报文时（不按序到达的报文，重复的报文）**

![image-20230214151439793](计算机网络.assets/image-20230214151439793.png)





#### D-SACK（Duplicate SACK）

从发送报文开始计时，当超过指定的时间后，**没有收到对方的 ACK 确认应答报文**，就会重发该数据

![image-20230214152150360](计算机网络.assets/image-20230214152150360.png)

![image-20230214152621014](计算机网络.assets/image-20230214152621014.png)

「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 DSACK，表示收到了重复的包。这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。

**D-SACK的好处**

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;



### 滑动窗口

单位：字节

**产生原因**

采用一应一答方式，每次都要等待确认应答，才能发送一个新的报文段，效率极低

所以引入了窗口

窗口大小就是指**无需等待确认应答**，而可以继续发送数据的最大值。



#### **采用累计确认**

![image-20230214155352196](计算机网络.assets/image-20230214155352196.png)



#### **窗口大小的决定因素**

窗口大小：TCP头部中的Windows字段，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。

通常窗口的大小是由**接收方的窗口大小**来决定的



#### **发送方的滑动窗口**

<img src="计算机网络.assets/image-20230214160047639.png" alt="image-20230214160047639" style="zoom:150%;" />



比如下面发送方先把发送窗口中的所有数据发送出去

![image-20230214160339564](计算机网络.assets/image-20230214160339564.png)

然后发送方收到了32-36字节的ACK，如果发送窗口大小不变，则发送窗口向后移动

![image-20230214160459056](计算机网络.assets/image-20230214160459056.png)



#### **滑动窗口的具体实现**

TCP 滑动窗口方案使用**三个指针**来跟踪在四个传输类别中的每一个类别中的**字节**。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。

![image-20230214160758491](计算机网络.assets/image-20230214160758491.png)

可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）



#### 接收方的滑动窗口

![image-20230214161142773](计算机网络.assets/image-20230214161142773.png)

* RCV.WND ：表示接收窗口的大小，它会通告给发送方
* RCV.NXT ：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节
* 指向 #4 的第一个字节是个相对指针，它需要 RCV.NXT 指针加上 RCV.WND 大小的偏移量，就可以指向 #4 的第一个字节了



#### 接收窗口和发送窗口的大小是相等的吗？

并不是完全相等, 新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。



### 流量控制

####基本

TCP提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量



举个栗子，假设

客户端是接收方，服务端是发送方
假设接收窗口和发送窗口相同，都为 200
假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响

![image-20230215111836492](计算机网络.assets/image-20230215111836492.png)

![image-20230215111850568](计算机网络.assets/image-20230215111850568.png)

#### 操作系统缓冲区与滑动窗口的关系

然而实际上，发送窗口和接收窗口会变动，因为发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，**会被操作系统调整**

**Example 1**

当应用程序没有及时读取缓存时，发送窗口和接收窗口的变化

考虑以下场景：

* 客户端作为发送方，服务端作为接收方，发送窗口和接收窗口初始大小为360 
* 服务端非常的繁忙，当收到客户端的数据时，**应用层**不能及时读取数据

![image-20230215112921659](计算机网络.assets/image-20230215112921659.png)

![image-20230215112942221](计算机网络.assets/image-20230215112942221.png)





**Example 2**

当服务端系统资源非常紧张的时候，**操心系统**可能会直接减少了**接收缓冲区**大小，这时应用程序又无法及时读取缓存数据，那么这时候就有严重的事情发生了，会出现数据包丢失的现象

**接收窗口实际上就是剩余的接收缓存**

![image-20230215113532264](计算机网络.assets/image-20230215113532264.png)

![image-20230215113556719](计算机网络.assets/image-20230215113556719.png)

所以，如果发生了先减少缓存（减小接收窗口），再收缩窗口（减小发送窗口），就会出现丢包的现象

为了防止这种情况发生，**TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时**
**间再减少缓存，这样就可以避免了丢包情况**



#### 窗口关闭

如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭

但是存在下面的问题：

![image-20230215121558961](计算机网络.assets/image-20230215121558961.png)

为了解决这个问题，TCP 为**每个连接**设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器

如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小

![image-20230215122105314](计算机网络.assets/image-20230215122105314.png)

窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 RST 报文来中断连接



#### 糊涂窗口

* 如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小
* 到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这
  几个字节，这就是糊涂窗口
* TCP + IP 头有 40 个字节，为了传输那几个字节的数据，开销太大



![image-20230215122956702](计算机网络.assets/image-20230215122956702.png)

![image-20230215123019189](计算机网络.assets/image-20230215123019189.png)

可以发现窗口不断减少了，并且发送的数据都是比较小的了

所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：

* 接收方可以通告一个小的窗口
* 而发送方可以发送小数据

于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了

* 让接收方不通告小窗口给发送方
* 让发送方避免发送小数据



**那么如何让接收方不通告小窗口呢？**

当「窗口大小」< min( MSS，缓存空间/2 ) ，就会向发送方通告窗口为 0 ，也就阻止了发送方再发数据过来

等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来



**怎么让发送方避免发送小数据呢？**
使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：

* 要等到窗口大小 >= MSS 或是 数据大小 >= MSS
* 收到之前发送数据的 ack 回包

只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。
另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh
这样的交互性比较强的程序，则需要关闭 Nagle 算法。
可以在 Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据
每个应用自己的特点来关闭）

```c
setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&value, sizeof(int));
```



### 拥塞控制

#### 拥塞控制 VS 流量控制

流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么

拥塞控制，是避免「发送方」的数据填满整个网络

#### 什么是拥塞窗口

拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的

#### 拥塞窗口的计算

发送窗口 `swnd` 和接收窗口` rwnd`是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是

`swnd = min(cwnd, rwnd)`

只要网络中没有出现拥塞（没有发生超时重传）， cwnd 就会增大；但网络中出现了拥塞（发生超时重传）， `cwnd` 就减少

#### 拥塞控制算法

##### 慢启动

慢启动的算法记住一个规则就行：**当发送方每收到一个ACK，拥塞窗口 cwnd 的大小就会加 1**

假定`cwnd == swnd`

* 连接建立完成后，一开始初始化 `cwnd = 1` ，表示可以传一个 MSS 大小的数据
* 当收到一个 ACK 确认应答后，`cwnd` 增加 1，于是一次能够发送 2 个
* 当收到 **2 个的 ACK 确认应答**后， `cwnd` 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个
* 当这 **4 个的 ACK 确认**到来的时候，每个确认 `cwnd` 增加 1， 4 个确认 `cwnd` 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个

![image-20230216145552360](计算机网络.assets/image-20230216145552360.png)

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量
当 `cwnd` < `sshresh` 时，使用慢启动算法
当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」



##### 拥塞避免

当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法

一般来说 `ssthresh` 的大小是 `65535` 字节。

拥塞避免算法的规则：**每当收到一个 ACK 时，cwnd 增加 1/cwnd**

接上前面的慢启动的栗子，现假定 ssthresh 为 8 
当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 `cwnd` 一共增加 1，于是这一次
能够发送 9 个 MSS 大小的数据，变成了**线性增长**

![image-20230216150043543](计算机网络.assets/image-20230216150043543.png)

##### 拥塞发生

条件：触发了重传机制

**发生超时重传的拥塞发生算法**

发生超时重传，

* `ssthresh` 设为 `cwnd/2` 
* `cwnd` 重置为 1

这种算法比较激进

![image-20230216150621353](计算机网络.assets/image-20230216150621353.png)

**发生快速重传的拥塞发生算法**

还有更好的方式，就是「快速重传算法」

条件：三个ACK

当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd ` 变化如下：

* `cwnd = cwnd/2` 
* `ssthresh = cwnd` 
* 进入快速恢复算法



##### 快速恢复

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈



进入快恢复前，`cwnd` 和 `ssthresh` 已被更新

* `cwnd = cwnd/2` 
* `ssthresh = cwnd` 

然后进入快速恢复算法

* 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）重传丢失的数据包
* 如果再收到重复的 ACK，那么 `cwnd` 增加 1（说明网络状态不错，可以加快对未传发送数据的传输）
* 如果收到新数据的 ACK 后，把 `cwnd` 设置为第一步中的 `ssthresh` 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，**也即再次进入拥塞避免状态**

![image-20230216151446141](计算机网络.assets/image-20230216151446141.png)

#### 总结

![image-20230216152439189](计算机网络.assets/image-20230216152439189.png)





# 网络层



# 数据链路层



# 物理层







