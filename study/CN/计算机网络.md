



# WEB页面请求过程

![image-20230201194009289](计算机网络.assets/image-20230201194009289.png)

## 1.HTTP

1. **浏览器做的第一步工作是解析 URL**

![image-20230201194231720](计算机网络.assets/image-20230201194231720.png)

![image-20230201194242046](计算机网络.assets/image-20230201194242046.png)

​	当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是 /index.html 或者 /default.html
​	这些文件，这样就不会发生混乱了

2. 生产HTTP请求报文

![image-20230201194939299](计算机网络.assets/image-20230201194939299.png)

![image-20230201194953305](计算机网络.assets/image-20230201194953305.png)

## 2. DNS

接下来需要委托操作系统把信息发向WEB服务器，这就需要找到WEB服务器域名对应的IP地址

<img src="计算机网络.assets/image-20230201195303296.png" alt="image-20230201195303296" style="zoom:67%;" />

**根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了**

![image-20230201195616612](计算机网络.assets/image-20230201195616612.png)

![image-20230201195632901](计算机网络.assets/image-20230201195632901.png)



## 3. 协议栈

通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈

![image-20230201200113599](计算机网络.assets/image-20230201200113599.png)





## 4. TCP

应用报文从套接字进入协议栈（HTTP基于TCP传输）

**TCP报文段格式**

<img src="计算机网络.assets/image-20230201200545934.png" alt="image-20230201200545934" style="zoom:67%;" />

<img src="计算机网络.assets/image-20230201200859346.png" alt="image-20230201200859346" style="zoom:67%;" />

Linux下的TCP连接

![image-20230201201920701](计算机网络.assets/image-20230201201920701.png)

HTTP请求报文不能超过MSS长度，如果超过，会进行分割

![image-20230201202448591](计算机网络.assets/image-20230201202448591.png)

![image-20230201202536116](计算机网络.assets/image-20230201202536116.png)

在握手成功之后，报文通过WEB服务器默认端口进入

## 5. IP

然后，TCP报文段需要通过协议栈中的IP模块将数据封装成网络包发送给通信对象

IP包头

![image-20230201203600151](计算机网络.assets/image-20230201203600151.png)

当存在多个网卡时，借助路由表来判断**哪个网卡作为源地址IP**，假设 Web 服务器的目标地址是 192.168.10.200

注意：源IP地址就是发送端网卡的IP地址，进行下图操作后，数据包从匹配条目的IFACE项（就是以太网网卡）发送

![image-20230201203934658](计算机网络.assets/image-20230201203934658.png)



## 6. MAC

生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部

MAC头部格式

![image-20230201205057492](计算机网络.assets/image-20230201205057492.png)

MAC 包头的协议类型只使用：0800 ： IP 协议     0806 ： ARP 协议
此时需要知道接收方的MAC地址，需要地址解析协议ARP！

<img src="计算机网络.assets/image-20230201205720728.png" alt="image-20230201205720728" style="zoom:67%;" />

存在ARP缓存

![image-20230201205841841](计算机网络.assets/image-20230201205841841.png)



## 网卡

协议栈的IP模块拿到数据包后，网卡驱动为包加上报头和起始帧定界符，末尾加上FCS（帧校验序列）

![image-20230202195514949](计算机网络.assets/image-20230202195514949.png)



## 交换机

交换机的端口**不核对**接收方MAC地址，而是直接将所有接收到的包放到缓冲区中

交换机根据MAC地址表查找MAC地址，然后将信息发送到对应的端口

如果找不到，则泛洪式广播

如果目的地址是广播地址，则向所有端口广播

MAC地址中的广播地址：FF:FF:FF:FF:FF:FF

<img src="计算机网络.assets/image-20230202200318354.png" alt="image-20230202200318354" style="zoom:67%;" />

## 路由器

交换机的端口不具有MAC地址，但是路由器的每个端口都有IP地址和MAC地址

路由器会对包尾的FCS进行校验

路由器会检查MAC头部，如果和自己端口的MAC地址匹配则接受（交换机不检查，直接接受）

然后查找路由表判断转发目标

将 目的网络号 和路由表中每个条目的子网掩码 相与，匹配，向对应接口转发

![image-20230202201050008](计算机网络.assets/image-20230202201050008.png)



接下来，根据网关列，转发IP数据包，有两种情况：

1. 网关列为空，此时说明IP数据报已经到达了对应网络，则IP数据报头部的IP地址就是目的地址，由ARP获取对应的MAC地址，将查询结果作为接收方的MAC地址
2. 网关列不为空，则数据报继续向该IP地址转发



## 服务器与客户端

层层拆封，提交上层

然后服务器端向客户端发送HTTP响应报文

客户端收到HTTP响应报文后，由浏览器负责渲染

客户端向服务器四挥手



## 从协议角度来看

案例：Bob用笔记本连接学校的以太网交换机，下载WEB页面(www.google.com)

![image-20230202203610788](计算机网络.assets/image-20230202203610788.png)



### 准备：DHCP UDP IP 和 以太网

这里ISP向学校提供DNS服务，所以DNS服务器不再学校里

1. Bob必须要有自己的IP地址，通过DHCP协议，Bob从运行在本地的DHCP服务器上获取配置

   * 在操作系统上生成DHCP请求报文

   * 这个报文被封装在 源端口68 (DHCP客户) 和 目的端口67 (DHCP服务器) 的UDP报文段中

   * UDP报文段被封装在 源IP地址（0.0.0.0）和 广播地址（255.255.255.255）的IP数据报中

2. 该DHCP报文被封装在目的地址FF:FF:FF:FF:FF:FF的帧中，该帧的源MAC地址就是Bob笔记本的MAC地址
3. 该帧会由交换机广播
4. **路由器的接口**（MAC地址为00:22:6B:45:1F) 收到该广播的以太网帧，经过数据的层层解封，提取出DHCP请求报文
5. 假设路由器中的服务器以 CIDR块 68.85.2.0/24 分配IP 地址，假设DHCP 服务器分配地址 68. 85. 2. 101 给Bob 的笔记本
   * DHCP 服务器生成包含这个**IP 地址**以及**DNS 服务器的IP 地址**( 68. 87. 71. 226) 、**默认网关路由器的IP 地址**
     ( 68. 85. 2. l ) 和**子网块**(68. 85. 2. 0/ 24) (等价为“网络掩码) 的一个DHCP ACK 报文
   * 该DHCP ACK报文被封装在源MAC 地址00:22:6B:45:1F:1B) , 目的MAC 地址(00:16:D3:23:68:8A)的以太网帧中

6. 交换机收到路由器发送的数据报，由于之前的**自学习**，交换机向指定端口发送帧
7. 经过层层解封，得到DHCP报文，Bob记录下它的IP 地址和它的DNS 服务器的IP 地址。它还在其IP 转发表中安装默认网关的地址
8. Bob准备处理WEB网页

![image-20230202203610788](计算机网络.assets/image-20230202203610788.png)

### DNS和ARP

Bob在浏览器输入www.google.com

1. 浏览器生成套接字，这个套接字向www.google.com发送HTTP请求，生成这个套接字需要域名www.google.com对应的ip地址，需要DNS
2. 操作系统生成DNS查询报文，www.google.com被放入DNS报文的问题串中，DNS报文被放在目的端口号53的UDP报文段中，该UDP 报文段则被放入具有IP 目的地址68. 87. 71. 226（之前通过DNCP的ACK报文获得），和源IP 地址68.85. 2. 101 的IP 数据报中
3. 此时Bob只知道网关路由器的IP地址（通过DHCP的ACK报文获得），但不知道网关路由器的MAC地址，需要用到ARP协议
4. Bob笔记本生成一个具有目的lP 地址68 . 85. 2. 1(默认网关）的ARP 查询报文将该ARP 报文放置在一个具有广播目的地址(FF: FF: FF:FF: FF:FF ) 的以太网帧中，向交换机发送这个帧，这个帧最终会被交付到网关路由器
5. 网关路由器连接学校的接口收到该帧，发现ARP报文中的目标IP地址68 . 85.2. 1 匹配其接口的IP 地址。网关路由器准备一个**ARP回答**，指示它的MAC 地址00: 22: 6B: 45 : 1F: 1B 对应IP 地址68. 85. 2. 1，这个ARP回答报文放在目的地址为00: 16: D3: 23: 68: 8A（Bob的笔记本）的帧中
6. Bob接收ARP回答，从中抽取出网关路由器的MAC地址( 00 : 22: 6B: 45: 1F: 1B)
7. 至此Bob获取了网关路由器的MAC地址
8. Bob向交换机发送目的IP地址68. 87. 71. 226 (DNS 服务器），目的MAC地址00:22 : 6B:45: 1F: 1B (网关路由器）的帧

![image-20230202203610788](计算机网络.assets/image-20230202203610788.png)

### 域内路由选择

1. 网关路由器收到该帧，抽取出目的IP地址（DNS服务器的IP地址），根据其路由表，转发到Comcast网络左边的路由器
2. Comcast网络中左边的路由器收到帧，拆出IP地址，根据转发表，选择出接口，转发表己根据Comcast 的域内协议（如RIP 、OSPF 或IS-IS）以及因特网的域间协议BGP所填写
3. 然后DNS报文到达DNS服务器，DNS抽取出DNS报文，在数据库中查找谷歌对应的IP地址的**源记录**，假设缓存命中，DNS服务器发送DNS回答报文
4. 该报文到达Bob笔记本，抽取出DNS服务器的IP地址

### TCP和HTTP

1. 因为Bob已经有了www.google.com（WEB服务器）的IP地址，所以可以生成TCP套接字（这个套接字为了向服务器发送HTTP GET报文），与此同时，Bob笔记本的套接字向WEB服务器的套接字**TCP三握手**，Bob首先生成目的端口号80（HTTP）的TCP SYN 报文段， 报文段放在目的地址64. 233. 169. 105的IP数据报中，该数据报放置在MAC 地址为00:22:68:45: IF: 1B ( 网关路由器）的帧中，并向交换机发送该帧
2. 包含TCP SYN的数据报被路由器转发，转发规则由域内路由协议，域间路由协议共同完成
3. 最终，包含TCP SYN 的数据报到达www. google. com，拆解出TCP SYN报文，该报文被送到端口号80的**欢迎套接字**，之后**生成连接套接字**，产生一个TCP SYNACK 报文段
4. 包含TCP SYNACK报文段的数据报到达Bob，进入Bob对应端口的套接字，进入连接状态
5. Bob 的浏览器生成包含要获取的URL 的HTTP GET 报文，发往WEB服务器
6. 在www. google. com 的HTTP 服务器从TCP 套接字读取HTTP GET 报文，生成一个HTTP 响应报文，将请求的Web 页内容放入HTTP 响应体中，并将报文发送进TCP 套接字中
7. 包含HTTP 回答报文的数据报到达Bob，Bob 的Web 浏览器程序从套接字读取HTTP 响应，从HTTP 响应体中抽取Web 网页的html, 并最终显示了Web 网页

​     











# 网络安全

## 基本概念

密钥（KA）：数字或者字符，作为加密算法的输入

加密算法：用加密一方的密钥和明文报文（m)  作为输入

解密算法：用解密一方的密钥和密文报文（KA（m)  ）作为输入

报文摘要:（Message Digest）

散列报文鉴别码（Hashed MAC，HMAC) : 直接使用密码散列函数实现报文鉴别的技术, 不需要进行加密

数字签名（Digital Signature）：在计算机网络中传送的报文可以使用数字签名来证明其真实来源

实体鉴别：通信双方的一方验证另一方身份的技术，常简称为鉴别，实体可以是人、客户进程或服务器进程

不重数（nonce）：用来应对重放攻击，不重数可以使用户把重复的实体鉴别请求和新的实体鉴别请求区分开

密钥分配中心（Key Distribution Center，KDC）：其任务就是给需要进行秘密通信的用户临时分配一个会话密钥

![image-20230128201113780](计算机网络.assets/image-20230128201113780.png)

![image-20230128200743914](计算机网络.assets/image-20230128200743914.png)

## 对称密钥密码体制和公钥密码体制

### 公钥密码体制产生原因

![image-20230128201511165](计算机网络.assets/image-20230128201511165.png)

![image-20230128202513612](计算机网络.assets/image-20230128202513612.png)

注意：

PK只能用来加密，不能用来解密

公钥密码体制通常用于会话密钥的建立

## 报文摘要和报文鉴别码

为什么有报文摘要？因为总比加密这么长的报文效果要好

下图间的密钥只在双方间共享

加密后的报文摘要附在报文后面，称为报文鉴别码（MAC）

对于发送方产生的报文x和其相应的报文摘要H(x)，攻击者不可能伪造出另一个报文y，使得y与x具有同样的报文摘要

报文摘要算法：MD-5 ， SHA-1

![image-20230128202725979](计算机网络.assets/image-20230128202725979.png)

![image-20230128204407122](计算机网络.assets/image-20230128204407122.png)

<img src="计算机网络.assets/image-20230128204623824.png" alt="image-20230128204623824" style="zoom:67%;" />



## 数字签名

![image-20230131194441930](计算机网络.assets/image-20230131194441930.png)

![image-20230131195029731](计算机网络.assets/image-20230131195029731.png)

![image-20230131195252867](计算机网络.assets/image-20230131195252867.png)

**上面这种数字签名存在问题**

![image-20230131195346948](计算机网络.assets/image-20230131195346948.png)

**所以用下面这种保密性数字签名**

![image-20230131195403818](计算机网络.assets/image-20230131195403818.png)



## 实体鉴别

不重数可以使用户把重复的实体鉴别请求和新的实体鉴别请求区分开

![image-20230131200353103](计算机网络.assets/image-20230131200353103.png)

![image-20230131200751397](计算机网络.assets/image-20230131200751397.png)

![image-20230131201502729](计算机网络.assets/image-20230131201502729.png)

![image-20230131201846925](计算机网络.assets/image-20230131201846925.png)

所以需要CA



## 密钥分发

### 对称密钥的分发

![image-20230131202540009](计算机网络.assets/image-20230131202540009.png)

![image-20230131202719167](计算机网络.assets/image-20230131202719167.png)

### 公钥的分发

随意分发公钥的安全隐患

![image-20230131202941949](计算机网络.assets/image-20230131202941949.png)

因此，需要有一个值得信赖的机构将公钥与其对应的实体（人或机器）进行绑定（binding）。这种机构被称为认证中心（Certification Authority，CA），一般由政府出资建立

需要发布公钥的用户可以让CA**为其公钥**签发一个证书（Certification），**证书中包含有公钥及其拥有者的身份标识信息**（人名、公司名或IP地址等）

![image-20230131204212390](计算机网络.assets/image-20230131204212390.png)

![image-20230124211637780](计算机网络.assets/image-20230124211637780.png)

公钥基础结构（Public Key Infrastructure，PKI）

![image-20230131204614680](计算机网络.assets/image-20230131204614680.png)







## 攻击手段

![image-20230128200627819](计算机网络.assets/image-20230128200627819.png)

<img src="计算机网络.assets/image-20230128200648802.png" alt="image-20230128200648802" style="zoom: 67%;" />

![image-20230131195950301](计算机网络.assets/image-20230131195950301.png)





# 应用层

## HTTP(Hyper Text Transfer Protocol)

### 一些术语

**Web页面(文档）**

是由**对象**组成的。一个对象只是一个文件，诸如一个HTML 文件、一个JPEG 图形、一个Java 小程序或一个视频片段这样的文件，且它们可通过一个URL 地址寻址。

多数Web 页面含有一个HTML基本文件(base HTML file) 以及几个引用对象

HTML 基本文件通过对象的URL 地址引用页面中的其他对象

**URL的组成：**

* 存放对象的服务器主机名

* 对象的路径名

  比如 http: //www. someSchoo1. edu/ someDepartment/ picture.gif

  www. someSchoo1. edu是主机名，/someDepartment/ picture. gif 就是路径名



### HTTP的基本思想

当用户请求一个**Web 页面**（如点击一个超链接）时，浏览器向服务器发出对该页面中所包含对象的HTTP请求报文， 服务器接收到请求并用服务器的服务器包含这些对象的HTTP 响应报文进行响应

使用TCP为支撑协议，客户和服务器分别向其套接字接口发送和接受报文，一旦客户端向套接字发送了报文，报文就脱离了客户端的控制，转而由TCP控制

![image-20230127205259259](计算机网络.assets/image-20230127205259259.png)



HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据
的「约定和规范」。

基于TCP/IP，采用请求-应答的通信模式

文本：字符、图片、视频、压缩包等

超文本：文字、图片、视频等的混合体，超链接可以从一个超文本跳转到另一个超文本，HTML是最常见的超文本

* 进程与进程之间通信，具体来说，是客户的浏览器进程和WEB服务器进程间的通信，通过TCP连接，互相发送HTTP请求报文和HTTP响应报文

![image-20230123193408210](计算机网络.assets/image-20230123193408210.png)

* 建立在TCP连接（熟知端口号80）之上
* 两点之间传输的双向协议

### 不同版本的HTTP

* HTTP1.0

采用非持续连接方式，即浏览器每次请求一个文件，都要与服务器建立TCP连接，收到响应后立即关闭TCP连接

每请求一个文档就要有两倍的RTT的开销。若一个网页上有很多引用对象（例如图片等），那么请求每一个对象都需要花费2RTT的时间

![image-20230123195231627](计算机网络.assets/image-20230123195231627.png)

为了减小时延，浏览器通常会建立多个并行的TCP连接同时请求多个对象。但是，这会大量占用万维网服务器的资源，特别是万维网服务器往往要同时服务于大量客户的请求，这会使其负担很重。

​	HTTP1.0 的连接方式

![image-20230128191332375](计算机网络.assets/image-20230128191332375.png)

* HTTP1.1

采用持续连接方式

报文的格式是**纯文本**形式的

万维网服务器在发送响应后仍然保持这条连接

HTTP/1.1的持续连接还可以使用流水线方式工作(浏览器在收到HTTP的响应报文之前就能够连续发送多个请求报文)

​	HTTP1.1的性能瓶颈

1. 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分；
   发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
2. 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队
   头阻塞；
3. 没有请求优先级控制；
4. 请求只能从客户端开始，服务器只能被动响应。

* HTTP报文格式

HTTP是面向文本的，其报文中的每一个字段都是一些ASCII码串，并且每个字段的长度都是不确定的。

方法和字段：

Host字段（首部字段）：用来指定服务器的域名

Content-Length 字段：表明本次回应的数据长度

Connection 字段：要求服务器使用 TCP 持久连接，以便其他请求复用

User_agent字段：指明用户代理（浏览器）这样服务器就可以为不同的用户代理发送相同对象的不同版本

<img src="计算机网络.assets/image-20230124202849053.png" alt="image-20230124202849053" style="zoom:67%;" />

正因为HTTP1.1以长连接为基础，所以在一个TCP连接中，客户端可以同时发出多个请求，可以采用管道传输

<img src="计算机网络.assets/image-20230124203538980.png" alt="image-20230124203538980" style="zoom:67%;" />	`

![image-20230123205434968](计算机网络.assets/image-20230123205434968.png)

Content-Type 字段：用于服务器回应时，告诉客户端，本次数据是什么格式

![image-20230123205602605](计算机网络.assets/image-20230123205602605.png)

![image-20230123200801071](计算机网络.assets/image-20230123200801071.png)



![image-20230123201001683](计算机网络.assets/image-20230123201001683.png)

![image-20230123204626034](计算机网络.assets/image-20230123204626034.png)

![image-20230123200511032](计算机网络.assets/image-20230123200511032.png)

### Get和Post有什么区别？

Get：请求从服务器**获取**资源

<img src="计算机网络.assets/image-20230123210047186.png" alt="image-20230123210047186" style="zoom: 67%;" />

Post：向 URI 指定的资源**提交**数据，数据就放在报文的 body 里。

<img src="计算机网络.assets/image-20230124201741388.png" alt="image-20230124201741388" style="zoom:67%;" />

* Get方法实体体为空，而Post方法实体体不为空
* HTTP响应报文的实体体中存放着请求的文档数据
* HTTP响应报文的Last_Modified首部行对既可能在本地客户也可能在网络缓存服务器上的对象缓存来说非常重要

### GET 和 POST 方法都是安全和幂等的吗？

安全: 请求方法不会「破坏」服务器上的资源

幂等: 多次执行相同的操作，结果都是「相同」的

GET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。
POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。

### HTTP的缺点

1. 无状态。解决方法：cookie
2. 明文传输，容易被窃取
3. 不安全 解决方法：TLS/SSL

### HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

1. 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
2. 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求
   出去，可以减少整体的响应时间

### HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

HTTP/2 相比 HTTP/1.1 性能上的改进：

1. 头部压缩

   如果多个请求头部一样或相似，就回消除重复部分——HPACK算法，：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

2. 二进制

   格式头信息和数据体都是二进制（而不是HTTP1.1的文本），并且统称为帧（frame）：头信息帧和数据帧。增加传输效率

<img src="计算机网络.assets/image-20230125214027372.png" alt="image-20230125214027372" style="zoom: 50%;" />

3. 数据流

   数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必
   须要对数据包做标记，指出它属于哪个回应。**每个请求或回应的所有数据包**，称为一个数据流（ Stream ）, 客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

4. 优先级

   客户端还可以指定**数据流的**优先级。优先级高的请求，服务器就先响应该请求。

<img src="计算机网络.assets/image-20230125215103568.png" alt="image-20230125215103568" style="zoom:50%;" />

5. 多路复用

   HTTP/2 是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。
   移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，大幅度提高了连接的利用率。

   <img src="计算机网络.assets/image-20230125215411710.png" alt="image-20230125215411710" style="zoom:50%;" />

6. 服务器推送

   HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以主动
   向客户端发送消息。
   举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给
   客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。

### HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？

HTTP/2 主要的问题在于，**多个 HTTP 请求在复用一个 TCP 连接**，下层的 TCP 协议是不知道有多少个
HTTP 请求的。所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有
的 HTTP 请求都必须等待这个丢了的包被重传回来。

* HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞，那么队列后请求也统统被阻塞住了
* HTTP/2 多个请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。

所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！

基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。

头部压缩算法升级成了QPack

HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 TLS/1.3 的三次握手。QUIC 直接把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。

<img src="计算机网络.assets/image-20230125220111796.png" alt="image-20230125220111796" style="zoom:67%;" />

<img src="计算机网络.assets/image-20230125220348330.png" alt="image-20230125220348330" style="zoom:80%;" />

## HTTPS

HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式

### HTTP与HTTPS有什么区别

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全
的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP
三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

<img src="计算机网络.assets/image-20230124204144362.png" alt="image-20230124204144362" style="zoom:50%;" />

### HTTPS的解决方案

* HTTP的**窃听**危机——**机密性**——HTTPS解决：采用**混合加密**

**混合加密**：保证信息的机密性，解决了窃听的风险

在通信建立**前**采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
在通信过程**中**全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

**为什么采用混合加密？**

对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但
速度慢。

<img src="计算机网络.assets/image-20230124205448727.png" alt="image-20230124205448727" style="zoom:67%;" />

* HTTP的**篡改**风险——**完整性**——HTTPS解决：采用**摘要算法**

**摘要算法**：用来实现完整性，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。

![image-20230124210706971](计算机网络.assets/image-20230124210706971.png)

* HTTP**的冒充风险**——**实体鉴别**——HTTPS解决：将服务器**公钥放入数字证书**中

客户端先向服务器端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密

有一个问题：如何保证公钥不被篡改和信任度？——解决方法：CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

![image-20230124211637780](计算机网络.assets/image-20230124211637780.png)

### HTTPS的连接过程

1. 客户端向服务器索要并验证服务器的公钥。
2. 双方协商生产「会话秘钥」。
3. 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是握手阶段。

**SSL/TLS四握手**

见小林图解网络P19

[点击这里](F:\Caoyan\program\cpp\计算机网络\亮白风格-图解网络-小林coding-v2.0.pdf)

## Cookie

背景：HTTP是无状态协议，需要Cookie来保留状态，需要万维网服务器能够识别用户，对无状态的HTTP进行状态化的技术

**Cookie的组件**

1. 在HTTP 响应报文中的一个cookie **首部行**； 
2. 在HTTP 请求报文中的一个cookie **首部行**； 

3. 在用户端系统中保留有一个cookie 文件，并由用户的浏览器进行管理； 

4. 位于Web 站点的一个后端数据库

工作流程

3. 这个HTTP响应报文包含有一个首部字段“Set-Cookie"的首部行

![image-20230123202036179](计算机网络.assets/image-20230123202036179.png)

![image-20230128195215429](计算机网络.assets/image-20230128195215429.png)



# 运输层

## 基本知识

**TCP中发送方和接收方都有各自的输入输出流，发送接收窗口**

### 端口号

端口号只具有本地意义

<img src="计算机网络.assets/image-20230217131344629.png" alt="image-20230217131344629" style="zoom:67%;" />

<img src="计算机网络.assets/image-20230217131740020.png" alt="image-20230217131740020" style="zoom:67%;" />















## TCP三握手四挥手

### 什么是TCP

面向连接的，可靠的，基于字节流的运输层协议

面向连接：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的

可靠的：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；

字节流：消息是「没有边界」的，所以无论我们消息有多大都可以进行传输。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃

**为什么需要TCP？**网络层的IP协议是不可靠的

### TCP头部格式

![image-20230217134348316](计算机网络.assets/image-20230217134348316.png)



* **序列号：**

  在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来**解决网络包乱序**问题。

  占32比特，取值范围0~232-1。当序号增加到最后一个时，下一个序号又回到0。用来指出`本TCP报文段数据载荷的第一个字节的序号`

* **确认应答号：**

  指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。用来解决不丢包的问题。

  占32比特，取值范围0~232-1。当确认号增加到最后一个时，下一个确认号又回到0。用来指出`期望收到对方下一个TCP报文段的数据载荷的第一个字节的序号`，同时也是对之前收到的所有数据的确认

* **控制位：**

  `ACK`：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 SYN包之外该位必须设置为 1 
  `RST`：复位TCP连接。当RST=1时，表明TCP连接中出现严重差错，必须释放连接，然后再重新建立连接。RST置1还用来拒绝一个非法的TCP报文段或拒绝打开一个TCP连接

  `SYN`：该位为 1 时，表示**希望建立连接**，并在其「序列号」的字段进行**序列号初始值的设定**, SYN为1的TCP报文段要么是一个`连接请求报文段`，要么是一个`连接响应报文段`
  `FIN`：该位为 1 时，表示今后**不会再有数据发送**，**希望断开连接**。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 FIN 位为 1 的 TCP 段

  `PSH`：推送标志位，**发送方**TCP把PSH置1，并立即创建一个TCP报文段发送出去，而不需要积累到足够多的数据再发送。**接收方**TCP收到PSH为1的TCP报文段，就尽快地交付给应用进程，而不再等到接收到足够多的数据才向上交付。

* **首部长度（数据偏移）：**以4字节为单位

* **窗口**：

  占16比特，该字段的取值以`字节`为单位。
  指出发送本报文段的一方的`rwnd`的大小，即接收缓存的可用空间大小，这用来表征接收方的接收能力
  实现流量控制

* **紧急指针：**

  当发送方有紧急数据时，可将紧急数据“插队”到发送缓存的最前面，并立刻封装到一个TCP报文段中进行发送。紧急指针会指出本报文段数据载荷部分包含了多长的紧急数据，紧急数据之后是普通数据。
  接收方收到紧急标志位为1的TCP报文段，会按照紧急指针字段的值从报文段数据载荷中取出紧急数据并直接上交应用进程，而不必在接收缓存中排队。

* **选项：**

  <img src="计算机网络.assets/image-20230217140114708.png" alt="image-20230217140114708" style="zoom: 80%;" />

* **填充：**确保TCP首部长度能被4字节整除

  



### TCP连接建立的准备

建立一个 TCP 连接是需要客户端与服务器端达成上述三个信息的共识

1. Socket：由 IP 地址和端口号组成

2. 序列号：用来解决乱序问题等

3. 窗口大小：用来做流量控制



**源IP地址，目的IP地址，源端口号，目的端口号可以唯一确定一个TCP连接**



理论上：

![image-20230208165115768](计算机网络.assets/image-20230208165115768.png)

但是服务端最大连接数达不到这个数量，因为：

1. 文件描述符限制：Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目
2. 内存限制：每个 TCP 连接都要占用一定内存，操作系统的内存是有限的



### TCP数据载荷长度计算方法

![image-20230208171730465](计算机网络.assets/image-20230208171730465.png)

其中 IP 总长度 和 IP 首部长度，在 IP 首部格式是已知的。TCP 首部长度，则是在 TCP 首部格式已知的，所以就可以求得 TCP 数据的长度



### TCP与UDP的区别

![image-20230208163347939](计算机网络.assets/image-20230208163347939.png)

<img src="计算机网络.assets/image-20230208165834993.png" alt="image-20230208165834993"  />

1. 连接

   TCP是面向连接的传输层协议，传输数据前先要建立连接。 UDP是不需要连接，即刻传输数据。

2. 服务对象

   TCP是一对一的两点服务，仅支持单播。 UDP 支持单播、多播、广播

3. 可靠性

   TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。 UDP 是尽最大努力交付，不保证可靠交付数据。

4. 拥塞控制、流量控制

   TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率

5. 首部开销

   TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 20 个字节，如果使用了「选项」字段则会变长，首部最大60字节。UDP 首部只有 8 个字节，并且是固定不变的，开销较小

6. 传输方式

   TCP 是流式传输，没有边界，但保证顺序和可靠。UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序

7. 分片不同

   TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要**传输丢失的这个分片**。
   UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层，但是如果中途丢了一个分片，则就需要**重传所有的数据包**，这样传输效率非常差，所以通常 UDP 的报文应该小于 MTU

8. UDP是面向应用报文的，TCP是面向字节流的

**应用场景**

TCP: FTP HTTP HTTPS

UDP: DNS SNMP 广播 音视频

TCP 有**可变长**的「选项」字段，而 UDP 头部长度则是**不会变化**的，无需多一个字段去记录UDP 的首部长度

UDP 头部有「包长度」字段，而 TCP 头部则没有「包长度」字段，因为首部长度需要是 4 字节的整数倍



### TCP三握手

![image-20230208171900633](计算机网络.assets/image-20230208171900633.png)

![image-20230208172143004](计算机网络.assets/image-20230208172143004.png)![image-20230208172220914](计算机网络.assets/image-20230208172220914.png)

![image-20230208172253781](计算机网络.assets/image-20230208172253781.png)

### TCP快速连接

说白了就是cookie的应用

<img src="计算机网络.assets/image-20230222104833615.png" alt="image-20230222104833615" style="zoom: 67%;" />

第二次请求时，cookie携带有TCP连接的信息，所以可以跳过三握手

Linux中，可以通过设置 `net.ipv4.tcp_fastopn` 内核参数，来打开 Fast Open 功能



### 为什么是“三”握手？

关键：为什么三次握手才可以初始化Socket、序列号和窗口大小并建立 TCP 连接（实际上就是交换连接需要的状态信息）

**首要原因：了防止旧的重复连接初始化造成混乱**

![image-20230208173222740](计算机网络.assets/image-20230208173222740.png)

<img src="计算机网络.assets/image-20230217141009676.png" alt="image-20230217141009676" style="zoom:67%;" />

如果是两次握手连接，就不能判断当前连接是否是历史连接，三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端因有足够的上下文来判断当前连接是否是历史连接



**原因二：同步双方初始序列号**

![image-20230208174021541](计算机网络.assets/image-20230208174021541.png)



**原因三：避免资源浪费**

![image-20230208174322956](计算机网络.assets/image-20230208174322956.png)

两次握手会造成消息滞留情况下，服务器重复接受无用的连接请求 SYN 报文，而造成重复分配资源

而三握手只会在最后一次握手成功后分配资源

**总结**

三握手：能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号

二握手：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号

四握手：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数



### **为什么客户端和服务端的初始序列号 ISN 是不相同的？**

如果一个已经失效的连接被重用了，但是该旧连接的历史报文还残留在网络中，如果序列号相同，那么就无法分辨出该报文是不是**历史报文**，如果历史报文被新的连接接收了，则会产生数据错乱。
所以，每次建立连接前重新初始化一个序列号主要是为了通信双方能够根据序号将不属于本连接的报文段丢弃。
另一方面是为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收



### 随机ISN的产生

RFC1948 中提出了一个较好的初始化序列号 ISN 随机生成算法。
ISN = M + F (localhost, localport, remotehost, remoteport)
M 是一个计时器，这个计时器每隔 4 毫秒加 1。
F 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择



### 为什么 TCP 层还需要 MSS 呢？

**关键：在运输层分片而不是在网络层分片，运输层分片重传时只要重传丢失的分组，但是网络层分片重传时需要重传所有分组**

![image-20230210132811006](计算机网络.assets/image-20230210132811006.png)

IP层有一个大于MTU的数据要发送，需要分片，目的主机组装这些分片，再上交给TCP

IP层没有超时重传机制，需要TCP控制超时和重传

接收方发现一个IP分片丢失，所有分片都要重传

当接收方发现 TCP 报文（头部 + 数据）的某一片丢失后（IP分片丢失），则不会响应 ACK 给对方，那么发送方的TCP 在超时后，就会重发「整个 TCP 报文（头部 + 数据）」

所以，为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，当 TCP 层发现数据超过 MSS 时，则就先会进行分片，**当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了**

这样，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传效率



### TCP建立连接时/中包丢失会发生什么？

1. **第一次握手 SYN 包丢失**

   当客户端发起的 TCP 第一次握手 SYN 包，在超时时间内没收到服务端的 ACK，就会在超时重传 SYN 数据包，每次超时重传的 RTO 是翻倍上涨的，直到 SYN 包的重传次数到达` tcp_syn_retries `值后，客户端不再发送 SYN 包

   ![image-20230221162303552](计算机网络.assets/image-20230221162303552.png)

2. **第二次握手 SYN、ACK 丢包**

   当第二次握手的 SYN、ACK 丢包时，客户端会超时重发 SYN 包，服务端也会超时重传 SYN、ACK 包，TCP 第二次握手 SYN、ACK 包的最大重传次数是通过 `tcp_synack_retries` 内核参数限制的，默认值是5，**服务器收到SYN时，会重置重传SYN,ACK的计时器**

<img src="计算机网络.assets/image-20230221163202215.png" alt="image-20230221163202215" style="zoom: 80%;" />

3. **第三次握手 ACK 丢包**

   ![image-20230221164339383](计算机网络.assets/image-20230221164339383.png)

* 服务端在重传 SYN、ACK 包时，超过了最大重传次数` tcp_synack_retries` ，于是服务端的 TCP连接主动断开了
* 客户端向服务端发送数据包时，由于服务端的 TCP 连接已经退出了，所以数据包一直在超时重传，共重传了 15 次， telnet 就断开了连接

4. **TCP 建立连接后重传数据包**

   TCP 建立连接后的数据包传输，最大超时重传次数是由`tcp_retries2` 指定，默认值是 15

5. **客户端就是不发送数据**

   TCP保活机制

   定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个「探测报文」，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序

   ```c
   net.ipv4.tcp_keepalive_time=7200	//表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制
   net.ipv4.tcp_keepalive_intvl=75		//表示每次检测间隔 75 秒
   net.ipv4.tcp_keepalive_probes=9		//表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接
   ```


**总结一下：**

当重传次数超过 `tcp_retries1` 就会指示 IP 层进行 MTU 探测、刷新路由等过程，**并不会断开TCP连接**，当重传次数超过 `tcp_retries2` 才会断开TCP流

`tcp_retries1` 和 `tcp_retries2` 两个重传次数都是受一个 timeout 值限制









### 关于SYN攻击

假设攻击者短时间**伪造不同 IP 地址**的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，**无法得到未知 IP 主机的 ACK 应答**，久而久之就会占满服务端的 **SYN 接收队列**，使得服务器不能为正常用户服务

<img src="计算机网络.assets/image-20230210135208989.png" alt="image-20230210135208989" style="zoom:67%;" />



**避免方法一**

队列快满时，丢弃SYN报文（对新的SYN返回RST），设置SYN_RCVD状态的最大连接数

此时网卡接收数据包的速度会大于内核处理速度，数据报会进入缓冲队列，可以调整这个缓冲队列的大小

**避免方法二**

Linux 内核的 SYN （未完成连接建立）队列与 Accpet （已完成连接建立）队列的工作：

<img src="计算机网络.assets/image-20230210140152408.png" alt="image-20230210140152408" style="zoom: 80%;" />

1. 当服务端接收到客户端的 SYN 报文时，会将其加入到内核的「 SYN 队列」

2. 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文

3. 服务端接收到 ACK 报文后，从「 SYN 队列」移除放入到「 Accept 队列」

4. 应用通过调用 accpet() socket 接口，从「 Accept 队列」取出连接

   **tcp_syncookies 的方式可以应对 SYN 攻击的方法：**

<img src="计算机网络.assets/image-20230210140315907.png" alt="image-20230210140315907" style="zoom:80%;" />

<img src="计算机网络.assets/image-20230210140332655.png" alt="image-20230210140332655" style="zoom: 80%;" />

1. 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」
2. 计算出一个 cookie 值，再以 SYN + ACK 中的「序列号」返回**客户端**，服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性。如果合法，**直接放入到「 Accept 队列」**
3. 最后应用通过调用 accpet() socket 接口，从「 Accept 队列」取出的连接



### TCP四挥手

客户端和服务端都可以主动断开连接

TCP规定终止标志位FIN等于1的TCP报文段即使不携带数据，也要消耗掉一个序号

![image-20230217142634962](计算机网络.assets/image-20230217142634962.png)



#### 为什么需要四挥手？

比如客户端向服务器发送FIN，代表客户端向服务器这个方向的连接断开，但是服务器还是可以向客户端发送数据



#### **为什么TIME_WAIT等于2MSL？**

首先要区分TTL和MSL：

MSL： Maximum Segment Lifetime，报文最大生存时间，超过这个时间报文会被丢弃

TTL：IP数据报可经过的最大路由数（最大跳数），在IP头部中

2MSL：客户端收到服务端的FIN，进入TIME_WAIT，但客户端随后发送的ACK报文丢失，从而导致服务端重发FIN，这样正好两个MSL

Linux中，内核代码中包含了TCP的TIME_WAIT时间（60s）。 2MSL 默认是 60 秒，那么一个 MSL 也就是 30 秒

```c
#define TCP_TIMEWAIT_LEN (60*HZ) /* how long to wait to destroy TIME-WAIT
```



#### 为什么需要TIME_WAIT状态？

##### TIME_WAIT过短

**原因一：防止旧连接数据包造成数据扰乱**

![image-20230211145808063](计算机网络.assets/image-20230211145808063.png)

如上图黄色框框服务端在关闭连接之前发送的 SEQ = 301 报文，被网络延迟了。
这时有相同端口的 TCP 连接被复用后，被延迟的 SEQ = 301 抵达了客户端，那么客户端是有可能正常接收这个过期的报文，这就会产生数据错乱等严重的问题。

所以，TCP 就设计出了这么一个机制，经过 2MSL 这个时间，**足以让两个方向上的数据包都被丢弃**，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。

TCP客户进程在发送完最后一个TCP确认报文段后，再经过2MSL时长，就可以使本次连接持续时间内所产生的的所有报文段都从网络中消失。这样就可以使下一个新的TCP连接中不会出现旧连接中的报文段

**原因二：保证连接的正常关闭**

![image-20230211150936944](计算机网络.assets/image-20230211150936944.png)

![image-20230217143021877](计算机网络.assets/image-20230217143021877.png)

注意，正常情况下TIME_WAIT比较长，如果最后一个ACK丢失，服务端会**重传**FIN报文

处于时间等待（TIME-WAIT）状态后要经过2MSL时长，可以确保TCP一个TCP确认报文段而进入关闭（CLOSED）状态。服务器进程能够收到最后**一**个TCP确认报文段而进入关闭（CLOSED）状态

##### TIME_WAIT过长

* 占用内存资源
* 占用端口资源，一个 TCP 连接至少消耗一个本地端口

具体来说

客户端一共只有65536个端口，端口满了，新的连接没发建立

因为TCP连接四元组，服务端理论上可以建立比较多的TCP连接，但是由于服务器的线程池只有固定数量的线程被拿来用于建立TCP连接，所以新连接可能无法建立



#### 如何优化TIME_WAIT?

**方法一：net.ipv4.tcp_tw_reuse 和 tcp_timestamps**

如下的 Linux 内核参数开启后，则可以复用处于 TIME_WAIT 的 socket 为新的连接所用

```c
net.ipv4.tcp_tw_reuse = 1
```

在这之前需要打开TCP时间戳的支持

```c
net.ipv4.tcp_timestamps=1（默认即为 1）
```

tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用connect() 函数时，**内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用**

这个时间戳的字段在 TCP 头部的「选项」里，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间戳
由于引入了时间戳，**在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃**



**方式二：程序中使用 SO_LINGER**

以通过设置 socket 选项，来设置调用 close 关闭连接行为

```c
struct linger so_linger;
so_linger.l_onoff = 1;
so_linger.l_linger = 0;
setsockopt(s, SOL_SOCKET, SO_LINGER, &so_linger,sizeof(so_linger));
```

如果l_onoff 为非 0， 且l_linger 值为 0，那么调用close 后，会立该发送一个RST 标志给对端，该TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT 状态，直接关闭
但这为跨越TIME_WAIT 状态提供了一个可能，不过是一个非常危险的行为，不值得提倡



#### 已经建立了连接，但客户端突然出现故障了怎么办？

TCP存在**保活机制**，该机制通过每隔一段时间，发送包含少量数据的**探测报文**监视TCP连接相关的活动，如果一段时间内没有检测到活动，判断该TCP死亡，通知上层

**保活机制的实现：TCP保活计时器**

<img src="计算机网络.assets/image-20230218135128559.png" alt="image-20230218135128559" style="zoom:67%;" />

**有下面三种情况：**

1. 探测报文被正常接收，那保活时间重置
2. 对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端可以响应，但由于没有该连接的有效信息，会产生一个 **RST 报文**，这样很快就会发现 TCP 连接已经被重置
3. 是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端
   后，连续几次无响应，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡





Linux内核中的参数：

tcp_keepalive_time=7200：表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接
相关的活动，则会启动保活机制
tcp_keepalive_intvl=75：表示每次检测间隔 75 秒；
tcp_keepalive_probes=9：表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。

**total time = tcp_keepalive_time + tcp_keepalive_intvl * tcp_keepalive_probes**



#### Socket编程

![image-20230212103831316](计算机网络.assets/image-20230212103831316.png)

* 服务端和客户端初始化 socket ，得到文件描述符；
* 服务端调用 bind ，将绑定在 IP 地址和端口;
* 服务端调用 listen ，进行监听；
* 服务端调用 accept ，等待客户端连接；
* 客户端调用 connect ，向服务器端的地址和端口发起连接请求；
* 服务端 accept 返回用于传输的 socket 的文件描述符；
* 客户端调用 write 写入数据；服务端调用 read 读取数据；
* 客户端断开连接时，会调用 close ，那么服务端 read 读取数据的时候，就会读取到了EOF ，待处理完数据后，服务端调用 close ，表示连接关闭

这里需要注意的是，**服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket**，后续用来传输数据

也就是说监听socket和传输数据的socket不一样，一个是欢迎套接字，一个是传输套接字

成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，**就像往一个文件流里面写东西一样**。

<img src="计算机网络.assets/image-20230212105524171.png" alt="image-20230212105524171" style="zoom:80%;" />



Linux内核中会维护两个队列：

未完成连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；

已完成连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；



现在通常认为 backlog 是 accept 队列。

但是上限值是内核参数 somaxconn 的大小，也就说 accpet 队列长度 = min(backlog,somaxconn)



<img src="计算机网络.assets/image-20230212110928938.png" alt="image-20230212110928938" style="zoom:80%;" />

应用程序从connect 调用返回，表示客户端到服务器端的单向连接建立成功，客户端进入ESTABLISHED状态。

服务器端协议栈使得 accept 阻塞调用返回，这个时候服务器端到客户端的单向连接也建立成功，服务端进入ESTABLISHED状态。

**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**



<img src="计算机网络.assets/image-20230212111442491.png" alt="image-20230212111442491" style="zoom: 80%;" />

* 客户端调用 close ，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入FIN_WAIT_1 ；
* 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，**应用程序可以通过 read 调用来感知这个 FIN 包**。**这个 EOF 会被放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；
* 接着，**当处理完数据后，自然就会读到 EOF** ，于是也调用 close 关闭它的套接字，这会使得客户端会发出一个 FIN 包，之后处于 LAST_ACK 状态；
* 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT ；
* 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
* 客户端经过 2MSL 时间之后，也进入 CLOSE 状态；



#### 几个问题

1. 为了方便调试服务器程序，一般会在服务端设置 SO_REUSEADDR 选项，这样服务器程序在重启后，可以立刻使用。这里设置SO_REUSEADDR 是不是就等价于对这个 socket 设置了内核中的 net.ipv4.tcp_tw_reuse=1 这个选项？

   tcp_tw_reuse 是内核选项，主要用在连接的发起方（客户端）。TIME_WAIT 状态的连接创建时间超过 1 秒后，新的连接才可以被复用，注意，这里是「连接的发起方」；

   SO_REUSEADDR 是用户态的选项，用于「连接的服务方」，用来告诉操作系统内核，如果端口已被占用，但是 TCP 连接状态位于 TIME_WAIT ，可以重用端口。如果端口忙，而 TCP 处于其他状态，重用会有 “Address already in use” 的错误信息。tcp_tw_reuse 是为了缩短 time_wait 的时间，避免出现大量的 time_wait 连接而占用系统资源，解决的是 accept 后的问题。
   SO_REUSEADDR 是为了解决 time_wait 状态带来的端口占用问题，以及支持同一个 port 对应多个
   ip，解决的是 bind 时的问题。

2. 如果客户端第四次挥手ack丢失，服务端超时重发的fin报文也丢失，客户端timewait时
   间超过了2msl，这个时候会发生什么？认为连接已经关闭吗？

   当客户端 timewait 时间超过了 2MSL，则客户端就直接进入关闭状态。
   服务端超时重发 fin 报文的次数如果超过 tcp_orphan_retries 大小后，服务端也会关闭 TCP 连接

3. （1）IP按MTU分片，如果某一片丢失则需要所有分片都重传；（2）IP没有重传机制，所以需要等TCP发送方超时才能重传；问题一：MSS跟IP的MTU分片相比，只是多了一步协商MSS值的过程，而IP的MTU可以看作是默认协商好就是1500字节，所以为什么协商后的MSS可以做到丢失后只发丢失的这一片来提高效率，而默认协商好1500字节的IP分片就需要所有片都重传呢？问题二：TCP MSS分片如果丢失了一片，是不是也需要
   发送方等待超时再重传？如果不是，MSS的协商如何能在超时前就直到丢了分片从而提高效率的呢？

   **问题一：**
   如果一个大的 TCP 报文是被 MTU 分片，那么只有「第一个分片」才具有 TCP 头部，后面的分片则没有 TCP 头部，接收方 IP 层只有重组了这些分片，才会认为是一个 TCP 报文，那么丢失了其中一个分片，接收方 IP 层就不会把 TCP 报文丢给 TCP 层，那么就会等待对方超时重传这一整个TCP 报文。
   如果一个大的 TCP 报文被 MSS 分片，那么所有「分片都具有 TCP 头部」，因为每个 MSS 分片的是具有 TCP 头部的TCP报文，那么其中一个 MSS 分片丢失，就只需要重传这一个分片就可以。
   **问题二：**
   TCP MSS分片如果丢失了一片，发送方没收到对方ACK应答，也是会触发超时重传的，因为TCP层是会保证数据的可靠交付。

4. 如果是服务提供方发起的 close ，然后引起过多的 time_wait 状态的 tcp 链接，time_wait 会影响服务端的端口吗？

   不会。
   如果客户端的 TIME_WAIT 状态过多，占满了所有端口资源，则会导致无法创建新连接。
   **客户端受端口资源限制：**
   客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新连接。
   **服务端受系统资源限制：**
   由于一个 TCP 四元组表示 TCP 连接，理论上服务端可以建立很多连接，服务端只监听一个端口，但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。所以当服务端出现大量 TIMEWAIT 时，系统资源容易被耗尽。





## TCP中的各种机制

### 重传机制

#### 超时重传

**产生条件**

数据包丢失或者确认应答丢失

![image-20230214145804749](计算机网络.assets/image-20230214145804749.png)

**超时重传时间太大或太小？**

![image-20230214150057742](计算机网络.assets/image-20230214150057742.png)

所以超时重传时间（RTO） 的值应该略大于报文往返 RTT 的值



**超时重传时间（RTO）的计算**

由于RTT会变化，所以RTO也会变化

![image-20230219112213940](计算机网络.assets/image-20230219112213940.png)

![image-20230214150638499](计算机网络.assets/image-20230214150638499.png)

在 Linux 下，α = 0.125，β = 0.25， μ = 1，∂ = 4。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍**。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送

从上面可以看出，计算RTO需要RTT，但是

<img src="计算机网络.assets/image-20230219111759296.png" alt="image-20230219111759296"  />

<img src="计算机网络.assets/image-20230219111933406.png" alt="image-20230219111933406" style="zoom:80%;" />





#### 快重传

**产生条件**

收到三个**相同**的ACK

<img src="计算机网络.assets/image-20230214151022045.png" alt="image-20230214151022045" style="zoom:80%;" />

![image-20230222110704725](计算机网络.assets/image-20230222110704725.png)

* 数据包 1 期望的下一个数据包 Seq 是 1，但是数据包 2 发送的 Seq 却是 10945，说明收到的是乱序数据包，于是回了数据包 3 ，还是同样的 Seq = 1，Ack = 1，这表明是重复的 ACK
* 数据包 4 和 6 依然是乱序的数据包，于是依然回了重复的 ACK
* 当对方收到三次重复的 ACK 后，于是就快速重传了 Seq = 1 、Len = 1368 的数据包 8
* 当收到重传的数据包后，发现 Seq = 1 是期望的数据包，于是就发送了个**确认收到快速重传的ACK**


以上案例在 TCP 三次握手时协商开启了**选择性确认 SACK**，因此一旦数据包丢失并收到重复 ACK ，即使在丢失数据包之后还成功接收了其他数据包，**也只需要重传丢失的数据包**。如果不启用 SACK，就必须重传丢失包之后的每个数据包。
如果要支持 SACK ，必须双方都要支持。在 Linux 下，可以通过 `net.ipv4.tcp_sack` 参数打开这个功能（Linux 2.4 后默认打开）



#### SACK（Selective Acknowledgement ）选择性确认

**产生原因**：介绍TCP的快重传和可靠传输时，TCP接收方只能对按序收到的数据中的最高序号给出确认。当发送方超时重传时，接收方之前已收到的未按序到达的数据也会被重传

这种方式需要在 TCP 头部「选项」字段里加一个 SACK 的东西，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。



**SACK产生于接收方收到异常报文时（不按序到达的报文，重复的报文）**

![image-20230214151439793](计算机网络.assets/image-20230214151439793.png)

<img src="计算机网络.assets/image-20230219113050492.png" alt="image-20230219113050492" style="zoom: 80%;" />



#### D-SACK（Duplicate SACK）

从发送报文开始计时，当超过指定的时间后，**没有收到对方的 ACK 确认应答报文**，就会重发该数据

![image-20230214152150360](计算机网络.assets/image-20230214152150360.png)

![image-20230214152621014](计算机网络.assets/image-20230214152621014.png)

「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 DSACK，表示收到了重复的包。这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。

**D-SACK的好处**

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;



### 滑动窗口

单位：字节

**产生原因**

采用一应一答方式，每次都要等待确认应答，才能发送一个新的报文段，效率极低

所以引入了窗口

窗口大小就是指**无需等待确认应答**，而可以继续发送数据的最大值。



#### **采用累计确认**

![image-20230214155352196](计算机网络.assets/image-20230214155352196.png)



#### **窗口大小的决定因素**

窗口大小：TCP头部中的Windows字段，这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。

通常窗口的大小是由**接收方的窗口大小**来决定的



#### **发送方的滑动窗口**

<img src="计算机网络.assets/image-20230214160047639.png" alt="image-20230214160047639" style="zoom:150%;" />



比如下面发送方先把发送窗口中的所有数据发送出去

![image-20230214160339564](计算机网络.assets/image-20230214160339564.png)

然后发送方收到了32-36字节的ACK，如果发送窗口大小不变，则发送窗口向后移动

![image-20230214160459056](计算机网络.assets/image-20230214160459056.png)



#### **滑动窗口的具体实现**

TCP 滑动窗口方案使用**三个指针**来跟踪在四个传输类别中的每一个类别中的**字节**。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。

![image-20230214160758491](计算机网络.assets/image-20230214160758491.png)

可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）



#### 接收方的滑动窗口

![image-20230214161142773](计算机网络.assets/image-20230214161142773.png)

* RCV.WND ：表示接收窗口的大小，它会通告给发送方
* RCV.NXT ：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节
* 指向 #4 的第一个字节是个相对指针，它需要 RCV.NXT 指针加上 RCV.WND 大小的偏移量，就可以指向 #4 的第一个字节了



#### 接收窗口和发送窗口的大小是相等的吗？

并不是完全相等，因为

1. 网络存在延迟
2. 发送窗口还受到拥塞窗口的影响



### 流量控制

####基本

TCP提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量

解决因发送方发送数据太快而导致接收方来不及接收，造成接收方的接收缓存溢出的问题

接收窗口的大小，是在 TCP 三次握手中协商好的，后续数据传输时，接收方发送确认应答 ACK 报文时，会携带当前的接收窗口的大小，以此来告知发送方

**TCP的滑动窗口以字节为单位**

<img src="计算机网络.assets/image-20230218135535991.png" alt="image-20230218135535991" style="zoom:67%;" />

举个栗子，假设

客户端是接收方，服务端是发送方
假设接收窗口和发送窗口相同，都为 200
假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响

![image-20230215111836492](计算机网络.assets/image-20230215111836492.png)

![image-20230215111850568](计算机网络.assets/image-20230215111850568.png)

#### 操作系统缓冲区与滑动窗口的关系

然而实际上，发送窗口和接收窗口会变动，因为发送窗口和接收窗口中所存放的字节数，都是放在操作系统内存缓冲区中的，而操作系统的缓冲区，**会被操作系统调整**

**Example 1**

当应用程序没有及时读取缓存时，发送窗口和接收窗口的变化

考虑以下场景：

* 客户端作为发送方，服务端作为接收方，发送窗口和接收窗口初始大小为360 
* 服务端非常的繁忙，当收到客户端的数据时，**应用层**不能及时读取数据

![image-20230215112921659](计算机网络.assets/image-20230215112921659.png)

![image-20230215112942221](计算机网络.assets/image-20230215112942221.png)





**Example 2**

当服务端系统资源非常紧张的时候，**操心系统**可能会直接减少了**接收缓冲区**大小，这时应用程序又无法及时读取缓存数据，那么这时候就有严重的事情发生了，会出现数据包丢失的现象

**接收窗口实际上就是剩余的接收缓存**

![image-20230215113532264](计算机网络.assets/image-20230215113532264.png)

![image-20230215113556719](计算机网络.assets/image-20230215113556719.png)

所以，如果发生了先减少缓存（减小接收窗口），再收缩窗口（减小发送窗口），就会出现丢包的现象

为了防止这种情况发生，**TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况**



#### 窗口关闭

如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭

但是存在下面的问题：

![image-20230215121558961](计算机网络.assets/image-20230215121558961.png)

为了解决这个问题，TCP 为**每个连接**设有一个持续定时器，只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器

如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小

![image-20230215122105314](计算机网络.assets/image-20230215122105314.png)

<img src="计算机网络.assets/image-20230218141240730.png" alt="image-20230218141240730" style="zoom:80%;" />

窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 RST 报文来中断连接

零窗口探测报文丢失了怎么办？答：零窗口探测报文也有重传计时器！



**wireshark具体分析**

假设接收方处理数据的速度跟不上接收数据的速度，缓存就会被占满，从而导致接收窗口为 0，当发送方接收到零窗口通知时，就会停止发送数据

如下图，可以看到接收方的窗口大小在不断的收缩至 0

<img src="计算机网络.assets/image-20230222113333451.png" alt="image-20230222113333451" style="zoom: 80%;" />

接着，发送方会定时发送窗口大小探测报文，以便及时知道接收方窗口大小的变化

![image-20230222113351438](计算机网络.assets/image-20230222113351438.png)

`ZeroWindow`是服务器发给客户端的零窗口报文，`Keep-Alive`是客户端发给服务器的窗口探测报文

可以发现，这些窗口探测报文以 3.4s、6.5s、13.5s 的间隔出现，说明超时时间会**翻倍**递增



**关于发送窗口的分析**

在 Wireshark 看到的 Windows size 也就是 " win = "，这不是发送窗口，**而是在向对方声明自己的接收窗口**



**发送窗口和 MSS 有什么关系？**

发送窗口决定了一口气能发多少字节，而 MSS 决定了这些字节要分多少包才能发完
举个例子，如果发送窗口为 16000 字节的情况下，如果 MSS 是 1000 字节，那就需要发送 1600/1000= 16 个包





#### 糊涂窗口

* 如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小
* 到最后，如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这
  几个字节，这就是糊涂窗口
* TCP + IP 头有 40 个字节，为了传输那几个字节的数据，开销太大



![image-20230215122956702](计算机网络.assets/image-20230215122956702.png)

![image-20230215123019189](计算机网络.assets/image-20230215123019189.png)

可以发现窗口不断减少了，并且发送的数据都是比较小的了

所以，糊涂窗口综合症的现象是可以发生在发送方和接收方：

* 接收方可以通告一个小的窗口
* 而发送方可以发送小数据

于是，要解决糊涂窗口综合症，就解决上面两个问题就可以了

* 让接收方不通告小窗口给发送方
* 让发送方避免发送小数据



**那么如何让接收方不通告小窗口呢？**

当「窗口大小」< min( MSS，缓存空间/2 ) ，就会向发送方通告窗口为 0 ，也就阻止了发送方再发数据过来

等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来



**怎么让发送方避免发送小数据呢？**
使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：

* 要等到窗口大小 >= MSS 或是 数据大小 >= MSS
* 收到之前发送数据的 ack 回包

只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件。
另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh
这样的交互性比较强的程序，则需要关闭 Nagle 算法。
可以在 Socket 设置 TCP_NODELAY 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据
每个应用自己的特点来关闭）

```c
setsockopt(sock_fd, IPPROTO_TCP, TCP_NODELAY, (char *)&value, sizeof(int));
```



### 拥塞控制

<img src="计算机网络.assets/image-20230218142326724.png" alt="image-20230218142326724" style="zoom:80%;" />

#### 拥塞控制 VS 流量控制

流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么

拥塞控制，是避免「发送方」的数据填满整个网络

<img src="计算机网络.assets/image-20230218141942661.png" alt="image-20230218141942661" style="zoom: 80%;" />

#### 什么是拥塞窗口

拥塞窗口 cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的

#### 拥塞窗口的计算

发送窗口 `swnd` 和接收窗口` rwnd`是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是

`swnd = min(cwnd, rwnd)`

只要网络中没有出现拥塞（没有发生超时重传）， cwnd 就会增大；但网络中出现了拥塞（发生超时重传）， `cwnd` 就减少

#### 拥塞控制算法

假设以下条件：

1. 数据是单方向传输的
2. 不受流量控制影响，即`swnd = cwnd`
3. 以MSS的个数为讨论问题的单位

##### 慢启动

慢启动的算法记住一个规则就行：**当发送方每收到一个ACK，拥塞窗口 cwnd 的大小就会加 1**

假定`cwnd == swnd`

* 连接建立完成后，一开始初始化 `cwnd = 1` ，表示可以传一个 MSS 大小的数据
* 当收到一个 ACK 确认应答后，`cwnd` 增加 1，于是一次能够发送 2 个
* 当收到 **2 个的 ACK 确认应答**后， `cwnd` 增加 2，于是就可以比之前多发2 个，所以这一次能够发送 4 个
* 当这 **4 个的 ACK 确认**到来的时候，每个确认 `cwnd` 增加 1， 4 个确认 `cwnd` 增加 4，于是就可以比之前多发 4 个，所以这一次能够发送 8 个

![image-20230216145552360](计算机网络.assets/image-20230216145552360.png)

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量
当 `cwnd` < `sshresh` 时，使用慢启动算法
当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」



##### 拥塞避免

当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法

一般来说 `ssthresh` 的大小是 `65535` 字节。

拥塞避免算法的规则：**每当收到一个 ACK 时，cwnd 增加 1/cwnd**

接上前面的慢启动的栗子，现假定 ssthresh 为 8 
当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 `cwnd` 一共增加 1，于是这一次
能够发送 9 个 MSS 大小的数据，变成了**线性增长**

![image-20230216150043543](计算机网络.assets/image-20230216150043543.png)

##### 拥塞发生

条件：触发了重传机制

**发生超时重传的拥塞发生算法**

发生超时重传，

* `ssthresh` 设为 `cwnd/2` 
* `cwnd` 重置为 1

这种算法比较激进

![image-20230216150621353](计算机网络.assets/image-20230216150621353.png)

**发生快速重传的拥塞发生算法**

还有更好的方式，就是「快速重传算法」

条件：三个ACK

当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传

这就要求接收方不要等待自己发送数据时才进行捎带确认，而是要立即发送确认，即使收到了失序的报文段也要立即发出对已收到的报文段的重复确认

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd ` 变化如下：

* `cwnd = cwnd/2` 
* `ssthresh = cwnd` 
* 进入快速恢复算法



##### 快速恢复

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈

进入快恢复前，`cwnd` 和 `ssthresh` 已被更新

* `cwnd = cwnd/2` 
* `ssthresh = cwnd` 

**然后进入快速恢复算法**

* 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思，因为有 3 个数据包在接收方的接收缓存中，网络中减少了3个报文段），重传丢失的数据包
* 如果再收到重复的 ACK，那么 `cwnd` 增加 1（说明网络状态不错，可以加快对未传发送数据的传输）
* 如果收到新数据的 ACK 后，把 `cwnd` 设置为第一步中的 `ssthresh` 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，**也即再次进入拥塞避免状态**

![image-20230216151446141](计算机网络.assets/image-20230216151446141.png)

#### 总结

![image-20230218145701854](计算机网络.assets/image-20230218145701854.png)

![image-20230216152439189](计算机网络.assets/image-20230216152439189.png)





### 延迟确认与 Nagle 算法

当我们 TCP 报文的承载的数据非常小的时候，例如几个字节，那么整个网络的效率是很低的，因为每个 TCP 报文中都会有 20 个字节的 TCP 头部，也会有 20 个字节的 IP 头部，而数据只有几个字节，所以在整个报文中有效数据占有的比重就会非常低

为了减少小报文的传输，可以采用下面两种方法：

Nagle 算法

延迟确认

#### Nagle 算法

* 没有已发送未确认报文时，立刻发送数据
* 存在未确认报文时，直到「没有已发送未确认报文」或「数据长度达到 MSS 大小」时，再发送数据

只要没满足上面条件中的一条，发送方一直在囤积数据，直到满足上面的发送条件

<img src="计算机网络.assets/image-20230223142952988.png" alt="image-20230223142952988" style="zoom:80%;" />



1. 一开始由于没有已发送未确认的报文，所以就立刻发了 H 字符
2. 接着，在还没收到对 H 字符的确认报文时，发送方就一直在囤积数据，直到收到了确认报文后
3. 此时没有已发送未确认的报文，于是就把囤积后的 ELL 字符一起发给了接收方
4. 待收到对 ELL 字符的确认报文后，于是把最后一个 O 字符发送了出去

可以看出，**Nagle 算法一定会有一个小报文**，也就是在最开始的时候

Nagle 算法默认是打开的

可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭



#### 延迟确认

事实上当没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP头，但却没有携带数据报文

TCP延迟确认机制:

* 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
* 当没有响应数据要发送时，ACK 将会**延迟一段时间**，以等待是否有响应数据可以一起发送
* 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK

<img src="计算机网络.assets/image-20230223143804861.png" alt="image-20230223143804861" style="zoom:80%;" />

<img src="计算机网络.assets/image-20230223144040534.png" alt="image-20230223144040534" style="zoom:67%;" />

关键就需要 `HZ` 这个数值大小，`HZ` 是跟系统的时钟频率有关，每个操作系统都不一样，这里 Linux系统中 `HZ` 大小是 `1000` ，如下图：

<img src="计算机网络.assets/image-20230223144206381.png" alt="image-20230223144206381" style="zoom: 67%;" />

<img src="计算机网络.assets/image-20230223144227839.png" alt="image-20230223144227839" style="zoom:67%;" />

#### 存在的问题

当 TCP 延迟确认 和 Nagle 算法混合使用时，会导致时耗增长，所以两个机制不要同时使用

<img src="计算机网络.assets/image-20230223144358823.png" alt="image-20230223144358823" style="zoom:67%;" />

很明显，这两个同时使用会造成额外的时延，这就会使得网络"很慢"的感觉



## TCP半连接全连接队列

### 基本知识

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

1. 半连接队列，也称 SYN 队列
2. 全连接队列，也称 accept 队列

服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列

服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 `RST` 包

![image-20230223150212540](计算机网络.assets/image-20230223150212540.png)



### syncookie

如果 SYN 半连接队列已满，只能丢弃连接吗？

并不是这样，**开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接**，在前面我们源码分析也可以看到这点，当开启了 syncookies 功能就不会丢弃连接
syncookies 是这么做的：服务器根据当前状态计算出一个值，放在己方发出的 SYN+ACK 报文中发出，当客户端返回 ACK 报文时，取出该值验证，如果合法，就认为连接建立成功，如下图所示

<img src="计算机网络.assets/image-20230224133658969.png" alt="image-20230224133658969" style="zoom:67%;" />



syncookies 参数主要有以下三个值：
0 值，表示关闭该功能；
1 值，表示仅当 SYN 半连接队列放不下时，再启用它；
2 值，表示无条件开启功能；
那么在应对 SYN 攻击时，只需要设置为 1 即可

**如何防御SYN攻击？**
增大半连接队列；
开启 tcp_syncookies 功能
减少 SYN+ACK 重传次数



## TCP性能提升

### 三握手性能提升

**客户端的优化**

三次握手建立连接的**首要目的是「同步序列号」**。只有同步了序列号才有可靠传输，TCP 许多特性都依赖于序列号实现，比如流量控制、丢包重传等，这也是三次握手中的报文称为 SYN 的原因，SYN 的全称就叫 Synchronize Sequence Numbers（同步序列号）

<img src="计算机网络.assets/image-20230225143922284.png" alt="image-20230225143922284" style="zoom:67%;" />

客户端发送SYN包，等待服务器回复SYN+ACK，如果没有收到SYN+ACK，客户端会重传SYN包，重发的次数由 `tcp_syn_retries `参数控制，默认是 `5` 次，每次超时的时间是上一次的 `2 `倍。第一次要经过`一个RTO`重传，第二次要`两个RTO`重传，第三次要`四个RTO`重传...

所以可以客户端可以降低超时重传次数，使服务器即使把错误暴露给客户端

**服务端优化**

1. 增加半连接队列，不能只单纯增大 `tcp_max_syn_backlog `的值，还需一同增大 `somaxconn` 和 `backlog`，也就是增大 `accept ` (全连接）队列。否则，只单纯增大 `tcp_max_syn_backlog` 是无效的

   **SYN 半连接队列和 accept 队列都是在 `listen()` 初始化的**

2. 增大服务器发送SYN -ACK的重发次数

   三握手的最后一步，服务器没有收到ACK，就会重发 SYN+ACK 报文，同时一直处于 SYN_RCV 状态
   当网络繁忙时，报文丢失就会变严重，此时应该调大重发次数。反之则可以调小重发次数。修改重发次数的方法是，调整 `tcp_synack_retries` 参数

3. tcp_synack_retries 的默认重试次数是 5 次，与客户端重传 SYN 类似，它的重传会经历 1、2、4、8、16 秒，最后一次重传后会继续等待 32 秒，如果服务端仍然没有收到 ACK，才会关闭连接，故共需要等待 63 秒

   **如果进程不能及时地调用 accept 函数，就会造成 accept 队列（也称全连接队列）溢出，最终导致建立好的 TCP 连接被丢弃**

3. 把 `tcp_abort_on_overflow` 设置为0

   tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：
   0 ：如果 accept 队列满了，那么 server 扔掉 client 发过来的 ack ；
   1 ：如果 accept 队列满了，server 发送一个 RST 包给 client，表示废掉这个握手过程和这个连接

   把 `tcp_abort_on_overflow` 设置为0, 那么客户端就会重传ack，如果服务器中的进程调用了 accept 读取了全连接队列中的数据，那么全连接队列就回有空位，这个时候客户端的ack就会被服务器接收，连接就会最终建立

   ![image-20230225150004728](计算机网络.assets/image-20230225150004728.png)

4. 增加全连接队列的长度

   `accept` 队列的长度取决于 `somaxconn` 和 `backlog` 之间的最小值，也就是 `min(somaxconn, backlog)`，
   其中：
   `somaxconn` 是 Linux 内核的参数，默认值是 `128`，可以通过 `net.core.somaxconn` 来设置其值；
   `backlog` 是 `listen(int sockfd, int backlog)` 函数中的 `backlog` 大小；

5. 如果遭受 SYN 攻击，应把 `tcp_syncookies` 参数设置为 1，表示仅在 SYN 队列满后开启 syncookie 功能，可以保证接下来正常的连接成功建立

**绕过三握手——使用TCP Fast Open**

三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送

<img src="计算机网络.assets/image-20230225150320785.png" alt="image-20230225150320785" style="zoom:50%;" />

![image-20230225150423692](计算机网络.assets/image-20230225150423692.png)

1. 客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 `Cookie` 为空，这表明客户端请求 Fast Open Cookie
2. 支持 TCP Fast Open 的服务器生成 `Cookie`，并将其置于 SYN-ACK 数据包中的 `Fast Open` 选项以发回客户端
3. 客户端收到 SYN-ACK 后，本地缓存 `Fast Open `选项中的 `Cookie`

之后

1. 客户端发送 SYN 报文，该报文包含「数据」以及此前记录的 Cookie；
2. 支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYNACK报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；**如果Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；**
3. 如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，这就减少了握手带来的 1 个 RTT 的时间消耗；
4. 客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」；
5. 此后的 TCP 连接的数据传输过程和非 TFO **的正常情况一致**

客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为Cookie 无效

开启了 TFO 功能，cookie 的值是存放到 TCP option 字段里的

在 Linux 系统中，可以通过设置 `tcp_fastopn` 内核参数，来打开 Fast Open 功能：



### 四挥手性能提升

客户端和服务端双方都可以主动断开连接，通常先关闭连接的一方称为主动方，后关闭连接的一方称为被动方

主动关闭连接的，才有 TIME_WAIT 状态

![image-20230225152418396](计算机网络.assets/image-20230225152418396.png)

**主动方的优化**

一些铺垫

* 注意，RST和FIN都可以关闭TCP连接

  RST是暴力关闭方式，可以不走四挥手流程

  FIN是四挥手正常关闭连接方式，它由进程调用 `close` 和 `shutdown` 函数发起 FIN 报文

* 调用了 close 函数， 意味着完全关闭了两个方向上的连接，此时，**调用了 close 函数的一方的连接叫做「孤儿连接」**，如果你用 netstat -p 命令，会发现连接对应的进程名为空
  使用 close 函数关闭连接太暴力。相反，shutdown 函数可以控制**只关闭一个方向**的连接

  <img src="计算机网络.assets/image-20230225153054363.png" alt="image-20230225153054363" style="zoom:50%;" />

  第二个参数决定断开连接的方式，主要有以下三种方式：
  `SHUT_RD(0)`：关闭连接的「读」方向，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数据进行 ACK，然后悄悄地丢弃。也就是说，对端还是会接收到ACK，在这种情况下根本不知道数据已经被丢弃了
  `SHUT_WR(1)`：关闭连接的「写」方向，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发送的数据，将被立即发送出去，并发送一个 FIN 报文给对端
  `SHUT_RDWR(2)`：相当于 SHUT_RD 和 SHUT_WR 操作各一次，关闭套接字的读和写两个方向

1. **FIN_WAIT1 状态的优化**

   在FIN_WAIT1时，当迟迟收不到返回的 ACK 时，连接就会一直处于 FIN_WAIT1 状态。此时，内核会定时重发FIN 报文，其中重发次数由 `tcp_orphan_retries `控制（注意，orphan 虽然是孤儿的意思，该参数却不只对孤儿连接有效，事实上，它对所有 FIN_WAIT1 状态下的连接都有效），默认值是 0，表示8次

   **对于普遍正常情况时，调低 tcp_orphan_retries 就已经可以了**。如果遇到恶意攻击，FIN 报文根本无法发送出去，这由 TCP 两个特性导致的：
   首先，TCP 必须保证报文是有序发送的，FIN 报文也不例外，当发送缓冲区还有数据没有发送时，FIN 报文也不能提前发送。
   其次，TCP 有流量控制功能，当接收方接收窗口为 0 时，发送方就不能再发送数据。所以，当攻击者下载大文件时，就可以通过接收窗口设为 0 ，这就会使得 FIN 报文都无法发送出去，那么连接会一直处于 FIN_WAIT1 状态

   解决这种问题的方法，是调整 `tcp_max_orphans` 参数，它定义了「孤儿连接」的最大数量

   综上所述

   当进程调用了 `close` 函数关闭连接，此时连接就会是「孤儿连接」，因为它无法再发送和接收数据。Linux 系统为了防止孤儿连接过多，导致系统资源长时间被占用，就提供了 `tcp_max_orphans` 参数。如果孤儿连接数量大于它，`新增的孤儿连接将不再走四次挥手`，而是`直接发送 RST 复位报文`强制关闭。

2. **FIN_WAIT2 状态的优化**

   当主动方收到 ACK 报文后，会处于 FIN_WAIT2 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送 FIN 报文，关闭对方的发送通道。
   这时，如果连接是用 `shutdown` 函数关闭的，连接可以一直处于 FIN_WAIT2 状态，因为它可能还可以发送或接收数据。但对于 `close` 函数关闭的`孤儿连接`，由于无法再发送和接收数据，所以这个状态不可以持续太久，而 `tcp_fin_timeout `控制了这个状态下连接的持续时长，默认值是 60 秒

   **它意味着对于孤儿连接（调用 close 关闭的连接），如果在 60 秒后还没有收到 FIN 报文，连接就会直接关闭**
   这个 60 秒不是随便决定的，它与 TIME_WAIT 状态持续的时间是相同的

3. **TIME_WAIT 状态的优化**

   

### 数据传输性能提升

**TCP 的传输速度，受制于发送窗口与接收窗口，以及网络设备传输能力**

TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区：

* 如果连接的内存配置过小，就无法充分使用网络带宽，TCP 传输效率就会降低

* 如果连接的内存配置过大，很容易把服务器资源耗尽，这样就会导致新连接无法建立

因此，我们必须理解 Linux 下 TCP 内存的用途，才能正确地配置内存大小



#### 滑动窗口如何影响传输速度

TCP 报文发出去后，并不会立马从内存中删除，因为重传时还需要用到它。由于 TCP 是内核维护的，所以`报文存放在内核缓冲区`。如果连接非常多，我们可以通过 `free` 命令观察到 `buff/cache` 内存是会增大。

正常情况，服务器的TCP报文中的窗口字段长度为2字节，，因此它最多能表达 65535 字节大小的窗口，也就是 64KB大小。这在当今高速网络下不够用，扩充方法如下：

在 TCP选项字段定义了窗口扩大因子，用于扩大 TCP 通告窗口，其值大小是 2^14，这样就使 TCP 的窗口大小从 16 位扩大为 30 位（2^16 * 2^ 14 = 2^30），所以此时窗口的最大值可以达到 1GB

Linux 中打开这一功能，需要把 `tcp_window_scaling` 配置设为 1（默认打开）

要使用窗口扩大选项，通讯双方必须在各自的 SYN 报文中发送这个选项：

* 主动建立连接的一方在 SYN 报文中发送这个选项
* 而被动建立连接的一方只有在收到带窗口扩大选项的 SYN 报文之后才能发送这个选项

接收窗口（接收方的缓存）可以无限大吗？这是不可能的，因为网络的传输能力是有限的，当发送方依据发送窗口，发送超过网络处理能力的报文时，路由器会直接丢弃这些报文。因此，缓冲区的内存并不是越大越好



#### 如何确定最大传输速度？

时延带宽积（决定了网络中飞行报文的总大小）

<img src="计算机网络.assets/image-20230226115111597.png" alt="image-20230226115111597" style="zoom:50%;" />

比如最大带宽是 100 MB/s，网络时延（RTT）是 10ms 时，意味着客户端到服务端的网络一共可以存放 100MB/s * 0.01s = 1MB 的字节
这个 1MB 是带宽和时延的乘积，所以它就叫「带宽时延积」（缩写为 BDP，Bandwidth DelayProduct）。同时，这 1MB 也表示「飞行中」的 TCP 报文大小，它们就在网络线路、路由器等网络设备上。如果飞行报文超过了 1 MB，就会导致网络过载，容易丢包

发送缓冲区与带宽时延积的关系：

* 如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包
* 如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。**所以，发送缓冲区的大小最好是往带宽时延积靠近**



#### 怎样调整缓冲区大小？

在 Linux 中发送缓冲区和接收缓冲都是可以用**参数调节**的。设置完后，Linux 会根据你设置的缓冲区进行**动态调节**

发送缓冲区的调节功能是**自动开启**的，而接收缓冲区则需要配置 `tcp_moderate_rcvbuf `为 1 来开启调节功能

* 调节发送缓冲区

  通过配置`tcp_wmem`实现

  发送缓冲区是**自行调节**的，当发送方发送的数据被确认后，并且没有新的数据要发送，就会把发送缓冲区的内存释放掉

  <img src="计算机网络.assets/image-20230226115601518.png" alt="image-20230226115601518" style="zoom: 80%;" />

* 调节接收缓冲区范围

  通过配置 `tcp_rmem` 实现

  接收缓冲区可以根据系统**空闲内存的大小**来调节接收窗口

  * 如果系统的空闲内存很多，就可以自动把缓冲区增大一些，这样传给对方的接收窗口也会变大，因而提升发送方发送的传输数据数量

  * 反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常工作

  * 通过 `tcp_mem` 配置可以知道内存是否紧张或充分

    <img src="计算机网络.assets/image-20230226120037911.png" alt="image-20230226120037911" style="zoom:80%;" />

  <img src="计算机网络.assets/image-20230226115706970.png" alt="image-20230226115706970" style="zoom:80%;" />



#### 数据传输性能提升总结

<img src="计算机网络.assets/image-20230226120155990.png" alt="image-20230226120155990" style="zoom: 67%;" />

TCP默认的滑动窗口最大值只有 64 KB，不满足当今的高速网络的要求，要想提升发送速度必须提升滑动窗口的上限，在 Linux 下是通过设置 `tcp_window_scaling` 为 1 做到的，此时最大值可高达 1GB

滑动窗口定义了网络中飞行报文的最大字节数，当它超过带宽时延积时，网络过载，就会发生丢包。而
当它小于带宽时延积时，就无法充分利用网络带宽。因此，滑动窗口的设置，必须参考带宽时延积

内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 `tcp_wmem` 和接收缓冲区 `tcp_rmem`。Linux 会对缓冲区`动态调节`，我们应该把缓冲区的上限`设置为带宽时延积`。发送缓冲区的调节功能是`自动打开`的，而接收缓冲区需要把 `tcp_moderate_rcvbuf` 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 `tcp_mem`

但需要注意的是，如果程序中的 socket 设置 `SO_SNDBUF` 和 `SO_RCVBUF`，则会关闭缓冲区的动态整功能

有效配置这些参数后，既能够最大程度地保持并发性，也能让资源充裕时连接传输速度达到最大值







# 网络层



# 数据链路层



# 物理层







